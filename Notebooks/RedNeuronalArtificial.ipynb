{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedNeuronalArtificial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JuTRztW1CTVE"
      },
      "outputs": [],
      "source": [
        "# Importar librerías para tratamiento de datos\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from plotnine.data import mpg\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pandas.api.types import CategoricalDtype\n",
        "from plotnine import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar Keras y librerías adicionales de sklearn\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "Hw3WGzE_CfEh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar DataSet \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "tDUWXhZ8CiQK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "# Cargando data \n",
        "data = pd.read_csv('https://raw.githubusercontent.com/niwdehu/ProyectoFinal_INF648/main/DataSets/ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mbaYleHqCmhh",
        "outputId": "f43a0006-20fe-40fd-a0dd-7316fb6203d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
              "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
              "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
              "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
              "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
              "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
              "\n",
              "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
              "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
              "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
              "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
              "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
              "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
              "\n",
              "                  MTRANS           NObeyesdad  \n",
              "0  Public_Transportation        Normal_Weight  \n",
              "1  Public_Transportation        Normal_Weight  \n",
              "2  Public_Transportation        Normal_Weight  \n",
              "3                Walking   Overweight_Level_I  \n",
              "4  Public_Transportation  Overweight_Level_II  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b595bb9-e384-4f60-b392-6d13ae66b133\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <th>FAVC</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CAEC</th>\n",
              "      <th>SMOKE</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>SCC</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>CALC</th>\n",
              "      <th>MTRANS</th>\n",
              "      <th>NObeyesdad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.62</td>\n",
              "      <td>64.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.52</td>\n",
              "      <td>56.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>77.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>87.0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Walking</td>\n",
              "      <td>Overweight_Level_I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.78</td>\n",
              "      <td>89.8</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Overweight_Level_II</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b595bb9-e384-4f60-b392-6d13ae66b133')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b595bb9-e384-4f60-b392-6d13ae66b133 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b595bb9-e384-4f60-b392-6d13ae66b133');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Agregando columna IMC = Peso/Altura^2\n",
        "data.isnull().sum()\n",
        "#peso (kg) / [estatura (m)]2\n",
        "data[\"IMC\"]= data[\"Weight\"]/(data[\"Height\"]*data[\"Height\"])\n"
      ],
      "metadata": {
        "id": "yiD3iou7DgpC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluando Variable IMC \n",
        "data[\"NObeyesdad\"].unique()\n",
        "order = ['Obesity_Type_III','Obesity_Type_II','Obesity_Type_I','Overweight_Level_II','Overweight_Level_I','Normal_Weight','Insufficient_Weight']\n",
        "sns.catplot(x=\"IMC\", y=\"NObeyesdad\", data=data,order=order, height=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "U4HzUB0eOFEt",
        "outputId": "751d62f8-c307-4b76-b817-3b7de110a01f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f5721dafc90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos el IMC como una dataset adicional y separamos X e y\n",
        "X_data = data.drop(\"NObeyesdad\",axis=1)\n",
        "IMC_data = pd.DataFrame(data[\"IMC\"])\n",
        "X_data = X_data.drop(\"IMC\",axis=1)\n",
        "y_data = pd.DataFrame(data[\"NObeyesdad\"])\n",
        "print(X_data.shape)\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geajd7t1JNzT",
        "outputId": "96eb9fc7-8d24-44f5-b546-4d8b2856be6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2111, 16)\n",
            "(2111, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea un método para transformar los datos categóricos a numéricos\n",
        "#Metodo que retorna el dataset convertido basado en preprocesDataset caso TITANIC del CURSO\n",
        "def fillColumnaCategorica(dataset):\n",
        "  datacopy = dataset.copy()\n",
        "\n",
        "  #REMOVER COLUMNA DURACION HEIGHT and WEIGHT\n",
        "  \n",
        "  datacopy = datacopy.drop(\"Height\", axis=1)\n",
        "  datacopy = datacopy.drop(\"Weight\", axis=1)\n",
        "  \n",
        "  \n",
        "    #Determinamos que variables son del tipo númerico y cuales son categóricas\n",
        "  numeric_columns = list()\n",
        "  categorical_columns = list()\n",
        "  dictionary_of_columns_with_index_to_categorical = dict()\n",
        "  dictionary_of_columns_with_categorical_to_index = dict()\n",
        "\n",
        "  for column in datacopy:\n",
        "    #Determinamos si la variable es numérica o no\n",
        "    if pd.api.types.is_numeric_dtype(datacopy[column]):\n",
        "      numeric_columns.append(column)\n",
        "    else:\n",
        "      #Modificamos el tipo de dato de la variable mediante \"astype\"\n",
        "      datacopy[column] = datacopy[column].astype(\"category\")\n",
        "\n",
        "      #Verificamos si el tipo de dato de la variable fue transformado a categórico correctamente\n",
        "      if not pd.api.types.is_categorical_dtype(datacopy[column]):\n",
        "        raise Exception(\"La columna {} no se transformó correctamente a categórica\".format(column))\n",
        "\n",
        "      dictionary_of_columns_with_index_to_categorical[column] = dict()\n",
        "      dictionary_of_columns_with_categorical_to_index[column] = dict()\n",
        "      \n",
        "      #Indexamos los valores (categorías), sin tomar en consideración los nulos, de la variable y guardamos esa información en los diccionarios\n",
        "      for index, category in enumerate(datacopy[column].cat.categories):\n",
        "        dictionary_of_columns_with_index_to_categorical[column][index] = category\n",
        "        dictionary_of_columns_with_categorical_to_index[column][category] = index\n",
        "      \n",
        "      categorical_columns.append(column)\n",
        "\n",
        "  #Transformamos a números los valores (categorías) de las variables categóricas sin considerar los nulos\n",
        "  datacopy.replace(dictionary_of_columns_with_categorical_to_index, inplace=True)\n",
        "\n",
        "  print(\"COLUMNAS NUMERICAS\", numeric_columns)\n",
        "  print(\"COLUMNAS CATEGORICAS\",categorical_columns)\n",
        "  print(\"DICCIONARIOS DE VALORES \")\n",
        "  print(dictionary_of_columns_with_index_to_categorical)\n",
        "  print(dictionary_of_columns_with_categorical_to_index)\n",
        "  \n",
        "\n",
        " \n",
        "  return datacopy"
      ],
      "metadata": {
        "id": "FnReRzlSE-YA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformamos los datos de \"X\" a valores numéricos categóricos\n",
        "preprocess_X_data = fillColumnaCategorica(X_data)\n",
        "#Guardamos nuestro dataset pre-procesado en formato pickle\n",
        "preprocess_X_data.to_pickle(\"preprocess_data.pkl\")\n",
        "preprocess_X_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "tG4FvGq7E_z5",
        "outputId": "2780dc22-0adb-4563-d59d-58c1cc1b0301"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COLUMNAS NUMERICAS ['Age', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
            "COLUMNAS CATEGORICAS ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
            "DICCIONARIOS DE VALORES \n",
            "{'Gender': {0: 'Female', 1: 'Male'}, 'family_history_with_overweight': {0: 'no', 1: 'yes'}, 'FAVC': {0: 'no', 1: 'yes'}, 'CAEC': {0: 'Always', 1: 'Frequently', 2: 'Sometimes', 3: 'no'}, 'SMOKE': {0: 'no', 1: 'yes'}, 'SCC': {0: 'no', 1: 'yes'}, 'CALC': {0: 'Always', 1: 'Frequently', 2: 'Sometimes', 3: 'no'}, 'MTRANS': {0: 'Automobile', 1: 'Bike', 2: 'Motorbike', 3: 'Public_Transportation', 4: 'Walking'}}\n",
            "{'Gender': {'Female': 0, 'Male': 1}, 'family_history_with_overweight': {'no': 0, 'yes': 1}, 'FAVC': {'no': 0, 'yes': 1}, 'CAEC': {'Always': 0, 'Frequently': 1, 'Sometimes': 2, 'no': 3}, 'SMOKE': {'no': 0, 'yes': 1}, 'SCC': {'no': 0, 'yes': 1}, 'CALC': {'Always': 0, 'Frequently': 1, 'Sometimes': 2, 'no': 3}, 'MTRANS': {'Automobile': 0, 'Bike': 1, 'Motorbike': 2, 'Public_Transportation': 3, 'Walking': 4}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Gender        Age  family_history_with_overweight  FAVC  FCVC  NCP  \\\n",
              "0          0  21.000000                               1     0   2.0  3.0   \n",
              "1          0  21.000000                               1     0   3.0  3.0   \n",
              "2          1  23.000000                               1     0   2.0  3.0   \n",
              "3          1  27.000000                               0     0   3.0  3.0   \n",
              "4          1  22.000000                               0     0   2.0  1.0   \n",
              "...      ...        ...                             ...   ...   ...  ...   \n",
              "2106       0  20.976842                               1     1   3.0  3.0   \n",
              "2107       0  21.982942                               1     1   3.0  3.0   \n",
              "2108       0  22.524036                               1     1   3.0  3.0   \n",
              "2109       0  24.361936                               1     1   3.0  3.0   \n",
              "2110       0  23.664709                               1     1   3.0  3.0   \n",
              "\n",
              "      CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  MTRANS  \n",
              "0        2      0  2.000000    0  0.000000  1.000000     3       3  \n",
              "1        2      1  3.000000    1  3.000000  0.000000     2       3  \n",
              "2        2      0  2.000000    0  2.000000  1.000000     1       3  \n",
              "3        2      0  2.000000    0  2.000000  0.000000     1       4  \n",
              "4        2      0  2.000000    0  0.000000  0.000000     2       3  \n",
              "...    ...    ...       ...  ...       ...       ...   ...     ...  \n",
              "2106     2      0  1.728139    0  1.676269  0.906247     2       3  \n",
              "2107     2      0  2.005130    0  1.341390  0.599270     2       3  \n",
              "2108     2      0  2.054193    0  1.414209  0.646288     2       3  \n",
              "2109     2      0  2.852339    0  1.139107  0.586035     2       3  \n",
              "2110     2      0  2.863513    0  1.026452  0.714137     2       3  \n",
              "\n",
              "[2111 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fba9931-84f4-4d7a-b951-23e760028c01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <th>FAVC</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CAEC</th>\n",
              "      <th>SMOKE</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>SCC</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>CALC</th>\n",
              "      <th>MTRANS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>0</td>\n",
              "      <td>20.976842</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.728139</td>\n",
              "      <td>0</td>\n",
              "      <td>1.676269</td>\n",
              "      <td>0.906247</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>0</td>\n",
              "      <td>21.982942</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.005130</td>\n",
              "      <td>0</td>\n",
              "      <td>1.341390</td>\n",
              "      <td>0.599270</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>0</td>\n",
              "      <td>22.524036</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.054193</td>\n",
              "      <td>0</td>\n",
              "      <td>1.414209</td>\n",
              "      <td>0.646288</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2109</th>\n",
              "      <td>0</td>\n",
              "      <td>24.361936</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.852339</td>\n",
              "      <td>0</td>\n",
              "      <td>1.139107</td>\n",
              "      <td>0.586035</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>0</td>\n",
              "      <td>23.664709</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.863513</td>\n",
              "      <td>0</td>\n",
              "      <td>1.026452</td>\n",
              "      <td>0.714137</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2111 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fba9931-84f4-4d7a-b951-23e760028c01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fba9931-84f4-4d7a-b951-23e760028c01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fba9931-84f4-4d7a-b951-23e760028c01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformamos los datos de \"y\" a valores numéricos categóricos ordinales\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "niveles = ['Insufficient_Weight','Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III' ]\n",
        "enc_niveles = OrdinalEncoder(categories=[niveles])\n",
        "enc_niveles.fit(y_data[[\"NObeyesdad\"]])\n",
        "preprocess_y_data=pd.DataFrame(enc_niveles.transform(y_data[[\"NObeyesdad\"]]))\n",
        "preprocess_y_data.columns = ['NObeyesdad']\n",
        "preprocess_y_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xT8TCoMABCj6",
        "outputId": "18c99719-96d7-427a-cfb4-3e9509f956a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   NObeyesdad\n",
              "0         1.0\n",
              "1         1.0\n",
              "2         1.0\n",
              "3         2.0\n",
              "4         3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e4fc37f-a59c-4bec-b6e6-3b66e82f2fc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NObeyesdad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e4fc37f-a59c-4bec-b6e6-3b66e82f2fc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e4fc37f-a59c-4bec-b6e6-3b66e82f2fc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e4fc37f-a59c-4bec-b6e6-3b66e82f2fc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mediante el método \"train_test_split\" separamos la data de entrenamiento y test, usaremos el 20% de la data para entrenar el modelo.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = preprocess_X_data\n",
        "y = preprocess_y_data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=21)"
      ],
      "metadata": {
        "id": "Zu5sSo8qWC-j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YVCOPywDL5iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Escalamos los datos a entrenar de tal manera que lu distribución tenga un valor promedio 0 y una desviación estándar de 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "x_train_scaled = sc_X.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "J5GCaR_YU26R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformamos la variable \"y\" en una vector de 7 dimensiones, para poderla utilizar en una red neuronal\n",
        "from keras.utils import np_utils\n",
        "dummy_y = np_utils.to_categorical(y_train)\n",
        "dummy_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzQujD6BdaGE",
        "outputId": "03ddb0d3-0a5d-4c34-e631-b96a0814fd53"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inicializar la Red Neuronal Artificial (RNA)\n",
        "classifier = Sequential()\n",
        "\n",
        "# La probabilidad de 0.1% es para seleccionar neuronas de una capa sean ignoradas durante el entrenamiento.\n",
        "p = 0.000\n",
        "\n",
        "# Se agregan las capas de entrada y primera capa oculta\n",
        "classifier.add(Dense(units = 20, kernel_initializer = \"random_normal\",  \n",
        "                     activation = \"relu\", input_dim = 14))\n",
        "classifier.add(Dropout(p))\n",
        "\n",
        "# Se agrega la segunda capa oculta\n",
        "classifier.add(Dense(units = 15, kernel_initializer = \"uniform\",  activation = \"relu\"))\n",
        "classifier.add(Dropout(p))\n",
        "\n",
        "# Se agrega la tercera capa oculta\n",
        "classifier.add(Dense(units = 30, kernel_initializer = \"uniform\",  activation = \"relu\"))\n",
        "classifier.add(Dropout(p))\n",
        "\n",
        "# Se agrega la cuarta capa oculta\n",
        "classifier.add(Dense(units = 10, kernel_initializer = \"uniform\",  activation = \"relu\"))\n",
        "classifier.add(Dropout(p))\n",
        "\n",
        "# Se agrega la capa de salida\n",
        "classifier.add(Dense(units = 7, kernel_initializer = \"uniform\",  activation = \"softmax\"))\n",
        "\n",
        "# Se compila la RNA\n",
        "classifier.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "nx9qXx3uXe8V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustamos la RNA al Conjunto de Entrenamiento y la entrenamos\n",
        "log = classifier.fit(x_train_scaled, dummy_y,  batch_size = 10, epochs = 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrLXP9fwYREe",
        "outputId": "8b673a25-dcfa-4549-d49a-18af164184e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "169/169 [==============================] - 1s 2ms/step - loss: 1.9156 - accuracy: 0.1925\n",
            "Epoch 2/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.5897 - accuracy: 0.2992\n",
            "Epoch 3/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.4915 - accuracy: 0.4443\n",
            "Epoch 4/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.4306 - accuracy: 0.4597\n",
            "Epoch 5/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.3578 - accuracy: 0.5095\n",
            "Epoch 6/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.2935 - accuracy: 0.5521\n",
            "Epoch 7/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.2433 - accuracy: 0.5658\n",
            "Epoch 8/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.2074 - accuracy: 0.5658\n",
            "Epoch 9/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.1740 - accuracy: 0.5865\n",
            "Epoch 10/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.1476 - accuracy: 0.5954\n",
            "Epoch 11/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.1253 - accuracy: 0.5841\n",
            "Epoch 12/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0992 - accuracy: 0.5841\n",
            "Epoch 13/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0731 - accuracy: 0.6114\n",
            "Epoch 14/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0641 - accuracy: 0.5977\n",
            "Epoch 15/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.5960\n",
            "Epoch 16/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0312 - accuracy: 0.6007\n",
            "Epoch 17/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0119 - accuracy: 0.6114\n",
            "Epoch 18/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1.0015 - accuracy: 0.6143\n",
            "Epoch 19/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.6126\n",
            "Epoch 20/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9722 - accuracy: 0.6209\n",
            "Epoch 21/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9569 - accuracy: 0.6392\n",
            "Epoch 22/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9561 - accuracy: 0.6280\n",
            "Epoch 23/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9423 - accuracy: 0.6374\n",
            "Epoch 24/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.6392\n",
            "Epoch 25/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.6440\n",
            "Epoch 26/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9169 - accuracy: 0.6363\n",
            "Epoch 27/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.6445\n",
            "Epoch 28/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.9049 - accuracy: 0.6440\n",
            "Epoch 29/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6451\n",
            "Epoch 30/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8907 - accuracy: 0.6552\n",
            "Epoch 31/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.6463\n",
            "Epoch 32/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6558\n",
            "Epoch 33/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.6576\n",
            "Epoch 34/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8715 - accuracy: 0.6677\n",
            "Epoch 35/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8675 - accuracy: 0.6671\n",
            "Epoch 36/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.6682\n",
            "Epoch 37/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8534 - accuracy: 0.6748\n",
            "Epoch 38/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8546 - accuracy: 0.6594\n",
            "Epoch 39/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8486 - accuracy: 0.6706\n",
            "Epoch 40/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8441 - accuracy: 0.6771\n",
            "Epoch 41/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8415 - accuracy: 0.6807\n",
            "Epoch 42/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8361 - accuracy: 0.6748\n",
            "Epoch 43/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.6742\n",
            "Epoch 44/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8270 - accuracy: 0.6789\n",
            "Epoch 45/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8253 - accuracy: 0.6801\n",
            "Epoch 46/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8226 - accuracy: 0.6783\n",
            "Epoch 47/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.6931\n",
            "Epoch 48/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6848\n",
            "Epoch 49/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6931\n",
            "Epoch 50/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.6931\n",
            "Epoch 51/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7988 - accuracy: 0.6931\n",
            "Epoch 52/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8018 - accuracy: 0.6967\n",
            "Epoch 53/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8045 - accuracy: 0.6878\n",
            "Epoch 54/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.7002\n",
            "Epoch 55/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7884 - accuracy: 0.7050\n",
            "Epoch 56/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7892 - accuracy: 0.7062\n",
            "Epoch 57/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7885 - accuracy: 0.7008\n",
            "Epoch 58/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.7038\n",
            "Epoch 59/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7760 - accuracy: 0.7085\n",
            "Epoch 60/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7794 - accuracy: 0.7156\n",
            "Epoch 61/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7826 - accuracy: 0.7062\n",
            "Epoch 62/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.7174\n",
            "Epoch 63/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7733 - accuracy: 0.7056\n",
            "Epoch 64/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7717 - accuracy: 0.7068\n",
            "Epoch 65/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7706 - accuracy: 0.7097\n",
            "Epoch 66/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7638 - accuracy: 0.7133\n",
            "Epoch 67/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7649 - accuracy: 0.6991\n",
            "Epoch 68/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.7156\n",
            "Epoch 69/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7576 - accuracy: 0.7233\n",
            "Epoch 70/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7570 - accuracy: 0.7162\n",
            "Epoch 71/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.7139\n",
            "Epoch 72/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7222\n",
            "Epoch 73/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.7239\n",
            "Epoch 74/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.7376\n",
            "Epoch 75/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7127\n",
            "Epoch 76/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7415 - accuracy: 0.7281\n",
            "Epoch 77/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7437 - accuracy: 0.7239\n",
            "Epoch 78/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7415 - accuracy: 0.7239\n",
            "Epoch 79/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.7281\n",
            "Epoch 80/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7349 - accuracy: 0.7269\n",
            "Epoch 81/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7331 - accuracy: 0.7316\n",
            "Epoch 82/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.7399\n",
            "Epoch 83/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7236 - accuracy: 0.7376\n",
            "Epoch 84/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7202 - accuracy: 0.7299\n",
            "Epoch 85/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.7382\n",
            "Epoch 86/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.7399\n",
            "Epoch 87/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.7352\n",
            "Epoch 88/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.7423\n",
            "Epoch 89/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.7411\n",
            "Epoch 90/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7154 - accuracy: 0.7441\n",
            "Epoch 91/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.7429\n",
            "Epoch 92/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.7352\n",
            "Epoch 93/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.7364\n",
            "Epoch 94/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7118 - accuracy: 0.7382\n",
            "Epoch 95/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.7299\n",
            "Epoch 96/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.7411\n",
            "Epoch 97/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.7322\n",
            "Epoch 98/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.7429\n",
            "Epoch 99/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7118 - accuracy: 0.7370\n",
            "Epoch 100/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.7435\n",
            "Epoch 101/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.7417\n",
            "Epoch 102/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.7459\n",
            "Epoch 103/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.7441\n",
            "Epoch 104/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.7541\n",
            "Epoch 105/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.7447\n",
            "Epoch 106/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.7488\n",
            "Epoch 107/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.7506\n",
            "Epoch 108/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.7524\n",
            "Epoch 109/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.7482\n",
            "Epoch 110/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7494\n",
            "Epoch 111/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.7500\n",
            "Epoch 112/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.7459\n",
            "Epoch 113/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.7577\n",
            "Epoch 114/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.7488\n",
            "Epoch 115/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.7553\n",
            "Epoch 116/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.7411\n",
            "Epoch 117/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.7524\n",
            "Epoch 118/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.7530\n",
            "Epoch 119/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.7524\n",
            "Epoch 120/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.7518\n",
            "Epoch 121/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.7589\n",
            "Epoch 122/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.7595\n",
            "Epoch 123/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.7524\n",
            "Epoch 124/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.7571\n",
            "Epoch 125/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.7565\n",
            "Epoch 126/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.7577\n",
            "Epoch 127/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7571\n",
            "Epoch 128/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7630\n",
            "Epoch 129/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.7589\n",
            "Epoch 130/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.7500\n",
            "Epoch 131/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7642\n",
            "Epoch 132/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.7541\n",
            "Epoch 133/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.7435\n",
            "Epoch 134/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7624\n",
            "Epoch 135/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.7553\n",
            "Epoch 136/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.7559\n",
            "Epoch 137/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.7725\n",
            "Epoch 138/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.7530\n",
            "Epoch 139/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.7601\n",
            "Epoch 140/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.7607\n",
            "Epoch 141/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7565\n",
            "Epoch 142/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7613\n",
            "Epoch 143/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7618\n",
            "Epoch 144/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7654\n",
            "Epoch 145/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.7607\n",
            "Epoch 146/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7607\n",
            "Epoch 147/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.7648\n",
            "Epoch 148/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.7666\n",
            "Epoch 149/1000\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.7601\n",
            "Epoch 150/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.7624\n",
            "Epoch 151/1000\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.6245 - accuracy: 0.7713\n",
            "Epoch 152/1000\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.6333 - accuracy: 0.7660\n",
            "Epoch 153/1000\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.6271 - accuracy: 0.7725\n",
            "Epoch 154/1000\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.7654\n",
            "Epoch 155/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.7654\n",
            "Epoch 156/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.7630\n",
            "Epoch 157/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7648\n",
            "Epoch 158/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7737\n",
            "Epoch 159/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7737\n",
            "Epoch 160/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.7855\n",
            "Epoch 161/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.7695\n",
            "Epoch 162/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7855\n",
            "Epoch 163/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.7755\n",
            "Epoch 164/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7796\n",
            "Epoch 165/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7844\n",
            "Epoch 166/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7820\n",
            "Epoch 167/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7737\n",
            "Epoch 168/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7784\n",
            "Epoch 169/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7784\n",
            "Epoch 170/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7767\n",
            "Epoch 171/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7903\n",
            "Epoch 172/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7802\n",
            "Epoch 173/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7814\n",
            "Epoch 174/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7909\n",
            "Epoch 175/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7915\n",
            "Epoch 176/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7903\n",
            "Epoch 177/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7832\n",
            "Epoch 178/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7873\n",
            "Epoch 179/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7867\n",
            "Epoch 180/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7873\n",
            "Epoch 181/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7980\n",
            "Epoch 182/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7873\n",
            "Epoch 183/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7832\n",
            "Epoch 184/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7980\n",
            "Epoch 185/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7879\n",
            "Epoch 186/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7950\n",
            "Epoch 187/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7879\n",
            "Epoch 188/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7932\n",
            "Epoch 189/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7950\n",
            "Epoch 190/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.8027\n",
            "Epoch 191/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.8004\n",
            "Epoch 192/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7855\n",
            "Epoch 193/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7938\n",
            "Epoch 194/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7998\n",
            "Epoch 195/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7938\n",
            "Epoch 196/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7968\n",
            "Epoch 197/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.8045\n",
            "Epoch 198/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7921\n",
            "Epoch 199/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7974\n",
            "Epoch 200/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.8004\n",
            "Epoch 201/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.8021\n",
            "Epoch 202/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7932\n",
            "Epoch 203/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.8039\n",
            "Epoch 204/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.8027\n",
            "Epoch 205/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.8069\n",
            "Epoch 206/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.8021\n",
            "Epoch 207/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.8021\n",
            "Epoch 208/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7962\n",
            "Epoch 209/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7998\n",
            "Epoch 210/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.8033\n",
            "Epoch 211/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.8075\n",
            "Epoch 212/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.8110\n",
            "Epoch 213/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.8057\n",
            "Epoch 214/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7986\n",
            "Epoch 215/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.8075\n",
            "Epoch 216/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7956\n",
            "Epoch 217/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.8128\n",
            "Epoch 218/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.8104\n",
            "Epoch 219/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.8063\n",
            "Epoch 220/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8164\n",
            "Epoch 221/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.8104\n",
            "Epoch 222/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.8134\n",
            "Epoch 223/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8116\n",
            "Epoch 224/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.8158\n",
            "Epoch 225/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.8110\n",
            "Epoch 226/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.8086\n",
            "Epoch 227/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.8027\n",
            "Epoch 228/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8235\n",
            "Epoch 229/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8092\n",
            "Epoch 230/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8152\n",
            "Epoch 231/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8152\n",
            "Epoch 232/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8164\n",
            "Epoch 233/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8098\n",
            "Epoch 234/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.8104\n",
            "Epoch 235/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.8223\n",
            "Epoch 236/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8205\n",
            "Epoch 237/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8086\n",
            "Epoch 238/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8169\n",
            "Epoch 239/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8075\n",
            "Epoch 240/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8193\n",
            "Epoch 241/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.8175\n",
            "Epoch 242/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8175\n",
            "Epoch 243/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8146\n",
            "Epoch 244/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8187\n",
            "Epoch 245/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8181\n",
            "Epoch 246/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.8158\n",
            "Epoch 247/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8211\n",
            "Epoch 248/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8211\n",
            "Epoch 249/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8217\n",
            "Epoch 250/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8223\n",
            "Epoch 251/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8193\n",
            "Epoch 252/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8294\n",
            "Epoch 253/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8140\n",
            "Epoch 254/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8246\n",
            "Epoch 255/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8241\n",
            "Epoch 256/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8246\n",
            "Epoch 257/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8223\n",
            "Epoch 258/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8235\n",
            "Epoch 259/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.8158\n",
            "Epoch 260/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8169\n",
            "Epoch 261/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8193\n",
            "Epoch 262/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8229\n",
            "Epoch 263/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8169\n",
            "Epoch 264/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8335\n",
            "Epoch 265/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8341\n",
            "Epoch 266/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8246\n",
            "Epoch 267/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8187\n",
            "Epoch 268/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8211\n",
            "Epoch 269/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8323\n",
            "Epoch 270/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8252\n",
            "Epoch 271/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8288\n",
            "Epoch 272/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8294\n",
            "Epoch 273/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8276\n",
            "Epoch 274/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8282\n",
            "Epoch 275/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8199\n",
            "Epoch 276/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8306\n",
            "Epoch 277/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8312\n",
            "Epoch 278/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8288\n",
            "Epoch 279/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8288\n",
            "Epoch 280/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8223\n",
            "Epoch 281/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8306\n",
            "Epoch 282/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8282\n",
            "Epoch 283/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8235\n",
            "Epoch 284/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8235\n",
            "Epoch 285/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8371\n",
            "Epoch 286/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8288\n",
            "Epoch 287/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8312\n",
            "Epoch 288/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8199\n",
            "Epoch 289/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8258\n",
            "Epoch 290/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8312\n",
            "Epoch 291/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8371\n",
            "Epoch 292/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8282\n",
            "Epoch 293/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8193\n",
            "Epoch 294/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8276\n",
            "Epoch 295/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8371\n",
            "Epoch 296/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8318\n",
            "Epoch 297/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8341\n",
            "Epoch 298/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8300\n",
            "Epoch 299/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8329\n",
            "Epoch 300/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8223\n",
            "Epoch 301/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8418\n",
            "Epoch 302/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8335\n",
            "Epoch 303/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8329\n",
            "Epoch 304/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8347\n",
            "Epoch 305/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8400\n",
            "Epoch 306/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8395\n",
            "Epoch 307/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8318\n",
            "Epoch 308/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8335\n",
            "Epoch 309/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8395\n",
            "Epoch 310/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8318\n",
            "Epoch 311/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8448\n",
            "Epoch 312/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8371\n",
            "Epoch 313/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8335\n",
            "Epoch 314/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8205\n",
            "Epoch 315/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8347\n",
            "Epoch 316/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8288\n",
            "Epoch 317/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8371\n",
            "Epoch 318/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8329\n",
            "Epoch 319/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8365\n",
            "Epoch 320/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8359\n",
            "Epoch 321/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8341\n",
            "Epoch 322/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8501\n",
            "Epoch 323/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8365\n",
            "Epoch 324/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8389\n",
            "Epoch 325/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8347\n",
            "Epoch 326/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8395\n",
            "Epoch 327/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8371\n",
            "Epoch 328/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8371\n",
            "Epoch 329/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8400\n",
            "Epoch 330/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8359\n",
            "Epoch 331/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8460\n",
            "Epoch 332/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8389\n",
            "Epoch 333/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8460\n",
            "Epoch 334/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8412\n",
            "Epoch 335/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8353\n",
            "Epoch 336/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8495\n",
            "Epoch 337/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8377\n",
            "Epoch 338/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8436\n",
            "Epoch 339/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8323\n",
            "Epoch 340/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8395\n",
            "Epoch 341/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8442\n",
            "Epoch 342/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8395\n",
            "Epoch 343/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8359\n",
            "Epoch 344/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8466\n",
            "Epoch 345/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8472\n",
            "Epoch 346/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8329\n",
            "Epoch 347/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8389\n",
            "Epoch 348/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8347\n",
            "Epoch 349/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8454\n",
            "Epoch 350/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8472\n",
            "Epoch 351/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8460\n",
            "Epoch 352/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8513\n",
            "Epoch 353/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8436\n",
            "Epoch 354/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8477\n",
            "Epoch 355/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8489\n",
            "Epoch 356/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8442\n",
            "Epoch 357/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8436\n",
            "Epoch 358/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8537\n",
            "Epoch 359/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8442\n",
            "Epoch 360/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8507\n",
            "Epoch 361/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8430\n",
            "Epoch 362/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8436\n",
            "Epoch 363/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8341\n",
            "Epoch 364/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8472\n",
            "Epoch 365/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8424\n",
            "Epoch 366/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8329\n",
            "Epoch 367/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8483\n",
            "Epoch 368/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8454\n",
            "Epoch 369/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8436\n",
            "Epoch 370/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8519\n",
            "Epoch 371/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8400\n",
            "Epoch 372/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8412\n",
            "Epoch 373/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8501\n",
            "Epoch 374/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8442\n",
            "Epoch 375/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8424\n",
            "Epoch 376/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8513\n",
            "Epoch 377/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8489\n",
            "Epoch 378/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8371\n",
            "Epoch 379/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8477\n",
            "Epoch 380/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8436\n",
            "Epoch 381/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8395\n",
            "Epoch 382/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8513\n",
            "Epoch 383/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8477\n",
            "Epoch 384/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8448\n",
            "Epoch 385/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8495\n",
            "Epoch 386/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8424\n",
            "Epoch 387/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8448\n",
            "Epoch 388/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8501\n",
            "Epoch 389/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8395\n",
            "Epoch 390/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8418\n",
            "Epoch 391/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8442\n",
            "Epoch 392/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8501\n",
            "Epoch 393/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8424\n",
            "Epoch 394/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8454\n",
            "Epoch 395/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8501\n",
            "Epoch 396/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8507\n",
            "Epoch 397/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8472\n",
            "Epoch 398/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8436\n",
            "Epoch 399/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8489\n",
            "Epoch 400/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8501\n",
            "Epoch 401/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8424\n",
            "Epoch 402/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8519\n",
            "Epoch 403/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8555\n",
            "Epoch 404/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8513\n",
            "Epoch 405/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8436\n",
            "Epoch 406/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8566\n",
            "Epoch 407/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8436\n",
            "Epoch 408/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8543\n",
            "Epoch 409/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8507\n",
            "Epoch 410/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8430\n",
            "Epoch 411/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8519\n",
            "Epoch 412/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8454\n",
            "Epoch 413/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8489\n",
            "Epoch 414/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8531\n",
            "Epoch 415/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8477\n",
            "Epoch 416/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8537\n",
            "Epoch 417/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8513\n",
            "Epoch 418/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8483\n",
            "Epoch 419/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8543\n",
            "Epoch 420/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8596\n",
            "Epoch 421/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8507\n",
            "Epoch 422/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8513\n",
            "Epoch 423/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8495\n",
            "Epoch 424/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8472\n",
            "Epoch 425/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8519\n",
            "Epoch 426/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8525\n",
            "Epoch 427/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8531\n",
            "Epoch 428/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8566\n",
            "Epoch 429/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8637\n",
            "Epoch 430/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8477\n",
            "Epoch 431/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8525\n",
            "Epoch 432/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8578\n",
            "Epoch 433/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8448\n",
            "Epoch 434/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8566\n",
            "Epoch 435/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8472\n",
            "Epoch 436/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8602\n",
            "Epoch 437/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8489\n",
            "Epoch 438/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8543\n",
            "Epoch 439/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8543\n",
            "Epoch 440/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8489\n",
            "Epoch 441/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8448\n",
            "Epoch 442/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8472\n",
            "Epoch 443/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8495\n",
            "Epoch 444/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8507\n",
            "Epoch 445/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8649\n",
            "Epoch 446/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8495\n",
            "Epoch 447/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8590\n",
            "Epoch 448/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8643\n",
            "Epoch 449/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8543\n",
            "Epoch 450/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8495\n",
            "Epoch 451/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8495\n",
            "Epoch 452/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8560\n",
            "Epoch 453/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8661\n",
            "Epoch 454/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8448\n",
            "Epoch 455/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8543\n",
            "Epoch 456/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8566\n",
            "Epoch 457/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8632\n",
            "Epoch 458/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8596\n",
            "Epoch 459/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8531\n",
            "Epoch 460/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8620\n",
            "Epoch 461/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8549\n",
            "Epoch 462/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8661\n",
            "Epoch 463/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8637\n",
            "Epoch 464/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8566\n",
            "Epoch 465/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8614\n",
            "Epoch 466/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8560\n",
            "Epoch 467/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8590\n",
            "Epoch 468/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8578\n",
            "Epoch 469/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8549\n",
            "Epoch 470/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8596\n",
            "Epoch 471/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8602\n",
            "Epoch 472/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8495\n",
            "Epoch 473/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8501\n",
            "Epoch 474/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8632\n",
            "Epoch 475/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8466\n",
            "Epoch 476/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8590\n",
            "Epoch 477/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8643\n",
            "Epoch 478/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8661\n",
            "Epoch 479/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8697\n",
            "Epoch 480/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8673\n",
            "Epoch 481/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8637\n",
            "Epoch 482/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8566\n",
            "Epoch 483/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8602\n",
            "Epoch 484/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8614\n",
            "Epoch 485/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8590\n",
            "Epoch 486/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8649\n",
            "Epoch 487/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8632\n",
            "Epoch 488/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8637\n",
            "Epoch 489/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8608\n",
            "Epoch 490/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8549\n",
            "Epoch 491/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8614\n",
            "Epoch 492/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8614\n",
            "Epoch 493/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8655\n",
            "Epoch 494/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8726\n",
            "Epoch 495/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8632\n",
            "Epoch 496/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8637\n",
            "Epoch 497/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8620\n",
            "Epoch 498/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8537\n",
            "Epoch 499/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8620\n",
            "Epoch 500/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8620\n",
            "Epoch 501/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8632\n",
            "Epoch 502/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8714\n",
            "Epoch 503/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8602\n",
            "Epoch 504/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8608\n",
            "Epoch 505/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8726\n",
            "Epoch 506/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8626\n",
            "Epoch 507/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8608\n",
            "Epoch 508/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8649\n",
            "Epoch 509/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8626\n",
            "Epoch 510/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8608\n",
            "Epoch 511/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8673\n",
            "Epoch 512/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8596\n",
            "Epoch 513/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8714\n",
            "Epoch 514/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8703\n",
            "Epoch 515/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8655\n",
            "Epoch 516/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8685\n",
            "Epoch 517/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8655\n",
            "Epoch 518/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8614\n",
            "Epoch 519/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8709\n",
            "Epoch 520/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8667\n",
            "Epoch 521/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8614\n",
            "Epoch 522/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8632\n",
            "Epoch 523/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8596\n",
            "Epoch 524/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8632\n",
            "Epoch 525/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8697\n",
            "Epoch 526/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8720\n",
            "Epoch 527/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8774\n",
            "Epoch 528/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8673\n",
            "Epoch 529/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8632\n",
            "Epoch 530/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8596\n",
            "Epoch 531/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8637\n",
            "Epoch 532/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8620\n",
            "Epoch 533/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8738\n",
            "Epoch 534/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8590\n",
            "Epoch 535/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8632\n",
            "Epoch 536/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8661\n",
            "Epoch 537/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8756\n",
            "Epoch 538/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8655\n",
            "Epoch 539/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8697\n",
            "Epoch 540/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8726\n",
            "Epoch 541/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8691\n",
            "Epoch 542/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8744\n",
            "Epoch 543/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8655\n",
            "Epoch 544/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8661\n",
            "Epoch 545/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8714\n",
            "Epoch 546/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8549\n",
            "Epoch 547/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8555\n",
            "Epoch 548/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8602\n",
            "Epoch 549/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8697\n",
            "Epoch 550/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8643\n",
            "Epoch 551/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8649\n",
            "Epoch 552/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8614\n",
            "Epoch 553/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8738\n",
            "Epoch 554/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8673\n",
            "Epoch 555/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8679\n",
            "Epoch 556/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8691\n",
            "Epoch 557/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8791\n",
            "Epoch 558/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8697\n",
            "Epoch 559/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8720\n",
            "Epoch 560/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8661\n",
            "Epoch 561/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8697\n",
            "Epoch 562/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8685\n",
            "Epoch 563/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8863\n",
            "Epoch 564/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8714\n",
            "Epoch 565/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8649\n",
            "Epoch 566/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8667\n",
            "Epoch 567/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8632\n",
            "Epoch 568/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8750\n",
            "Epoch 569/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8578\n",
            "Epoch 570/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8673\n",
            "Epoch 571/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8750\n",
            "Epoch 572/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8738\n",
            "Epoch 573/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8691\n",
            "Epoch 574/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8726\n",
            "Epoch 575/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8786\n",
            "Epoch 576/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8821\n",
            "Epoch 577/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8726\n",
            "Epoch 578/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8732\n",
            "Epoch 579/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8720\n",
            "Epoch 580/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8685\n",
            "Epoch 581/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8756\n",
            "Epoch 582/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8673\n",
            "Epoch 583/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8709\n",
            "Epoch 584/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8726\n",
            "Epoch 585/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8709\n",
            "Epoch 586/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8756\n",
            "Epoch 587/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8720\n",
            "Epoch 588/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8714\n",
            "Epoch 589/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8655\n",
            "Epoch 590/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8679\n",
            "Epoch 591/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8691\n",
            "Epoch 592/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8786\n",
            "Epoch 593/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8726\n",
            "Epoch 594/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8726\n",
            "Epoch 595/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8827\n",
            "Epoch 596/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8762\n",
            "Epoch 597/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8697\n",
            "Epoch 598/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8655\n",
            "Epoch 599/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8791\n",
            "Epoch 600/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8637\n",
            "Epoch 601/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8750\n",
            "Epoch 602/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8667\n",
            "Epoch 603/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8750\n",
            "Epoch 604/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8691\n",
            "Epoch 605/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8797\n",
            "Epoch 606/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8750\n",
            "Epoch 607/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8661\n",
            "Epoch 608/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8614\n",
            "Epoch 609/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8697\n",
            "Epoch 610/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8762\n",
            "Epoch 611/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8637\n",
            "Epoch 612/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8738\n",
            "Epoch 613/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8750\n",
            "Epoch 614/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8827\n",
            "Epoch 615/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8791\n",
            "Epoch 616/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8685\n",
            "Epoch 617/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8703\n",
            "Epoch 618/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8833\n",
            "Epoch 619/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8750\n",
            "Epoch 620/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8720\n",
            "Epoch 621/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8750\n",
            "Epoch 622/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8750\n",
            "Epoch 623/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8703\n",
            "Epoch 624/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8809\n",
            "Epoch 625/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8797\n",
            "Epoch 626/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8714\n",
            "Epoch 627/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8703\n",
            "Epoch 628/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3917 - accuracy: 0.8756\n",
            "Epoch 629/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8774\n",
            "Epoch 630/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3703 - accuracy: 0.8774\n",
            "Epoch 631/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3530 - accuracy: 0.8774\n",
            "Epoch 632/1000\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.3546 - accuracy: 0.8780\n",
            "Epoch 633/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3631 - accuracy: 0.8809\n",
            "Epoch 634/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8821\n",
            "Epoch 635/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8750\n",
            "Epoch 636/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8815\n",
            "Epoch 637/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8857\n",
            "Epoch 638/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8786\n",
            "Epoch 639/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8726\n",
            "Epoch 640/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8780\n",
            "Epoch 641/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8886\n",
            "Epoch 642/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8874\n",
            "Epoch 643/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8809\n",
            "Epoch 644/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8768\n",
            "Epoch 645/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8797\n",
            "Epoch 646/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8833\n",
            "Epoch 647/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8857\n",
            "Epoch 648/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8839\n",
            "Epoch 649/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8774\n",
            "Epoch 650/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8845\n",
            "Epoch 651/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8720\n",
            "Epoch 652/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8809\n",
            "Epoch 653/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8821\n",
            "Epoch 654/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8637\n",
            "Epoch 655/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8863\n",
            "Epoch 656/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8916\n",
            "Epoch 657/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8857\n",
            "Epoch 658/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8916\n",
            "Epoch 659/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8928\n",
            "Epoch 660/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8857\n",
            "Epoch 661/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8732\n",
            "Epoch 662/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8649\n",
            "Epoch 663/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8827\n",
            "Epoch 664/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8809\n",
            "Epoch 665/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8791\n",
            "Epoch 666/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8821\n",
            "Epoch 667/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8797\n",
            "Epoch 668/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8916\n",
            "Epoch 669/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8732\n",
            "Epoch 670/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8886\n",
            "Epoch 671/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8791\n",
            "Epoch 672/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8839\n",
            "Epoch 673/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8845\n",
            "Epoch 674/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8809\n",
            "Epoch 675/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8780\n",
            "Epoch 676/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8833\n",
            "Epoch 677/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8839\n",
            "Epoch 678/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8791\n",
            "Epoch 679/1000\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8815\n",
            "Epoch 680/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8833\n",
            "Epoch 681/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8951\n",
            "Epoch 682/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8880\n",
            "Epoch 683/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8673\n",
            "Epoch 684/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8809\n",
            "Epoch 685/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8839\n",
            "Epoch 686/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8886\n",
            "Epoch 687/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8940\n",
            "Epoch 688/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8880\n",
            "Epoch 689/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8833\n",
            "Epoch 690/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8892\n",
            "Epoch 691/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8768\n",
            "Epoch 692/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8874\n",
            "Epoch 693/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8880\n",
            "Epoch 694/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8851\n",
            "Epoch 695/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8898\n",
            "Epoch 696/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8821\n",
            "Epoch 697/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8892\n",
            "Epoch 698/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8851\n",
            "Epoch 699/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8904\n",
            "Epoch 700/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8874\n",
            "Epoch 701/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8928\n",
            "Epoch 702/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8857\n",
            "Epoch 703/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8797\n",
            "Epoch 704/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8898\n",
            "Epoch 705/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8904\n",
            "Epoch 706/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8833\n",
            "Epoch 707/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8916\n",
            "Epoch 708/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8922\n",
            "Epoch 709/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8868\n",
            "Epoch 710/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8922\n",
            "Epoch 711/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8863\n",
            "Epoch 712/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8833\n",
            "Epoch 713/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8886\n",
            "Epoch 714/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8957\n",
            "Epoch 715/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8851\n",
            "Epoch 716/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8863\n",
            "Epoch 717/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8940\n",
            "Epoch 718/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8845\n",
            "Epoch 719/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8981\n",
            "Epoch 720/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8851\n",
            "Epoch 721/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8916\n",
            "Epoch 722/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8892\n",
            "Epoch 723/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8892\n",
            "Epoch 724/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8768\n",
            "Epoch 725/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8863\n",
            "Epoch 726/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8874\n",
            "Epoch 727/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8916\n",
            "Epoch 728/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8898\n",
            "Epoch 729/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8863\n",
            "Epoch 730/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8910\n",
            "Epoch 731/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8886\n",
            "Epoch 732/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8845\n",
            "Epoch 733/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8957\n",
            "Epoch 734/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8857\n",
            "Epoch 735/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8940\n",
            "Epoch 736/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8898\n",
            "Epoch 737/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8839\n",
            "Epoch 738/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8916\n",
            "Epoch 739/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8839\n",
            "Epoch 740/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8898\n",
            "Epoch 741/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8969\n",
            "Epoch 742/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8934\n",
            "Epoch 743/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8975\n",
            "Epoch 744/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8981\n",
            "Epoch 745/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8934\n",
            "Epoch 746/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8904\n",
            "Epoch 747/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8809\n",
            "Epoch 748/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8880\n",
            "Epoch 749/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8679\n",
            "Epoch 750/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8886\n",
            "Epoch 751/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8963\n",
            "Epoch 752/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8934\n",
            "Epoch 753/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8851\n",
            "Epoch 754/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.9052\n",
            "Epoch 755/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8999\n",
            "Epoch 756/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8845\n",
            "Epoch 757/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8774\n",
            "Epoch 758/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8857\n",
            "Epoch 759/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8821\n",
            "Epoch 760/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8916\n",
            "Epoch 761/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.9023\n",
            "Epoch 762/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8916\n",
            "Epoch 763/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8922\n",
            "Epoch 764/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8999\n",
            "Epoch 765/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8951\n",
            "Epoch 766/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8904\n",
            "Epoch 767/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8928\n",
            "Epoch 768/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8910\n",
            "Epoch 769/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8904\n",
            "Epoch 770/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8951\n",
            "Epoch 771/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.9005\n",
            "Epoch 772/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8868\n",
            "Epoch 773/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8845\n",
            "Epoch 774/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8786\n",
            "Epoch 775/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8874\n",
            "Epoch 776/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8833\n",
            "Epoch 777/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8898\n",
            "Epoch 778/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8892\n",
            "Epoch 779/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8815\n",
            "Epoch 780/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8898\n",
            "Epoch 781/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8987\n",
            "Epoch 782/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8934\n",
            "Epoch 783/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8928\n",
            "Epoch 784/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8963\n",
            "Epoch 785/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8928\n",
            "Epoch 786/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8904\n",
            "Epoch 787/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8975\n",
            "Epoch 788/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8945\n",
            "Epoch 789/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8863\n",
            "Epoch 790/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8999\n",
            "Epoch 791/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8940\n",
            "Epoch 792/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8916\n",
            "Epoch 793/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8892\n",
            "Epoch 794/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8987\n",
            "Epoch 795/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8963\n",
            "Epoch 796/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8922\n",
            "Epoch 797/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8934\n",
            "Epoch 798/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8922\n",
            "Epoch 799/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8880\n",
            "Epoch 800/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8951\n",
            "Epoch 801/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8940\n",
            "Epoch 802/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8981\n",
            "Epoch 803/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8981\n",
            "Epoch 804/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8928\n",
            "Epoch 805/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8922\n",
            "Epoch 806/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8963\n",
            "Epoch 807/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8922\n",
            "Epoch 808/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8981\n",
            "Epoch 809/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8957\n",
            "Epoch 810/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8975\n",
            "Epoch 811/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8945\n",
            "Epoch 812/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8940\n",
            "Epoch 813/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8880\n",
            "Epoch 814/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8904\n",
            "Epoch 815/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8898\n",
            "Epoch 816/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8940\n",
            "Epoch 817/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8993\n",
            "Epoch 818/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8833\n",
            "Epoch 819/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8815\n",
            "Epoch 820/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8940\n",
            "Epoch 821/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8999\n",
            "Epoch 822/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8993\n",
            "Epoch 823/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8863\n",
            "Epoch 824/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8993\n",
            "Epoch 825/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8780\n",
            "Epoch 826/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8987\n",
            "Epoch 827/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8922\n",
            "Epoch 828/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.9011\n",
            "Epoch 829/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8957\n",
            "Epoch 830/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8732\n",
            "Epoch 831/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8945\n",
            "Epoch 832/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.9017\n",
            "Epoch 833/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8940\n",
            "Epoch 834/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.9058\n",
            "Epoch 835/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.9011\n",
            "Epoch 836/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.9028\n",
            "Epoch 837/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9040\n",
            "Epoch 838/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8857\n",
            "Epoch 839/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8904\n",
            "Epoch 840/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8922\n",
            "Epoch 841/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8815\n",
            "Epoch 842/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9011\n",
            "Epoch 843/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.9034\n",
            "Epoch 844/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.9040\n",
            "Epoch 845/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.9023\n",
            "Epoch 846/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8945\n",
            "Epoch 847/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9040\n",
            "Epoch 848/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.9052\n",
            "Epoch 849/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8910\n",
            "Epoch 850/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8874\n",
            "Epoch 851/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.9011\n",
            "Epoch 852/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8957\n",
            "Epoch 853/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8969\n",
            "Epoch 854/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8851\n",
            "Epoch 855/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8940\n",
            "Epoch 856/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8969\n",
            "Epoch 857/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.9011\n",
            "Epoch 858/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8993\n",
            "Epoch 859/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8993\n",
            "Epoch 860/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.9028\n",
            "Epoch 861/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8993\n",
            "Epoch 862/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8963\n",
            "Epoch 863/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8969\n",
            "Epoch 864/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8886\n",
            "Epoch 865/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8981\n",
            "Epoch 866/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8957\n",
            "Epoch 867/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.9023\n",
            "Epoch 868/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.9017\n",
            "Epoch 869/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9034\n",
            "Epoch 870/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8940\n",
            "Epoch 871/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8922\n",
            "Epoch 872/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8957\n",
            "Epoch 873/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8987\n",
            "Epoch 874/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8993\n",
            "Epoch 875/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8922\n",
            "Epoch 876/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8999\n",
            "Epoch 877/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.9040\n",
            "Epoch 878/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8945\n",
            "Epoch 879/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8898\n",
            "Epoch 880/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8975\n",
            "Epoch 881/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.9005\n",
            "Epoch 882/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.9040\n",
            "Epoch 883/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.9011\n",
            "Epoch 884/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8945\n",
            "Epoch 885/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9046\n",
            "Epoch 886/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.9034\n",
            "Epoch 887/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8916\n",
            "Epoch 888/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8993\n",
            "Epoch 889/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.9023\n",
            "Epoch 890/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9023\n",
            "Epoch 891/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8957\n",
            "Epoch 892/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.9082\n",
            "Epoch 893/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9070\n",
            "Epoch 894/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8963\n",
            "Epoch 895/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8863\n",
            "Epoch 896/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8993\n",
            "Epoch 897/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.9040\n",
            "Epoch 898/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9117\n",
            "Epoch 899/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.9034\n",
            "Epoch 900/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8999\n",
            "Epoch 901/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9028\n",
            "Epoch 902/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8904\n",
            "Epoch 903/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.9023\n",
            "Epoch 904/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9088\n",
            "Epoch 905/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9117\n",
            "Epoch 906/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.9040\n",
            "Epoch 907/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9082\n",
            "Epoch 908/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8987\n",
            "Epoch 909/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8975\n",
            "Epoch 910/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8910\n",
            "Epoch 911/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.9011\n",
            "Epoch 912/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9046\n",
            "Epoch 913/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9088\n",
            "Epoch 914/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.9040\n",
            "Epoch 915/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8993\n",
            "Epoch 916/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8987\n",
            "Epoch 917/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9082\n",
            "Epoch 918/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.9017\n",
            "Epoch 919/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.9017\n",
            "Epoch 920/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.9088\n",
            "Epoch 921/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.9040\n",
            "Epoch 922/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.9100\n",
            "Epoch 923/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.9064\n",
            "Epoch 924/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8898\n",
            "Epoch 925/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.9117\n",
            "Epoch 926/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.9088\n",
            "Epoch 927/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.9094\n",
            "Epoch 928/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8987\n",
            "Epoch 929/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.9129\n",
            "Epoch 930/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8975\n",
            "Epoch 931/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.9034\n",
            "Epoch 932/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.9129\n",
            "Epoch 933/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.9094\n",
            "Epoch 934/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.9040\n",
            "Epoch 935/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9058\n",
            "Epoch 936/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.9046\n",
            "Epoch 937/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8999\n",
            "Epoch 938/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9147\n",
            "Epoch 939/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.9023\n",
            "Epoch 940/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.9023\n",
            "Epoch 941/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.9064\n",
            "Epoch 942/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8993\n",
            "Epoch 943/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8993\n",
            "Epoch 944/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.9052\n",
            "Epoch 945/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.9052\n",
            "Epoch 946/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.9076\n",
            "Epoch 947/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.9123\n",
            "Epoch 948/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9117\n",
            "Epoch 949/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9100\n",
            "Epoch 950/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.9076\n",
            "Epoch 951/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.9046\n",
            "Epoch 952/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.9058\n",
            "Epoch 953/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9011\n",
            "Epoch 954/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.9082\n",
            "Epoch 955/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.9070\n",
            "Epoch 956/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8987\n",
            "Epoch 957/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.9076\n",
            "Epoch 958/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.9064\n",
            "Epoch 959/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.9005\n",
            "Epoch 960/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9070\n",
            "Epoch 961/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9117\n",
            "Epoch 962/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9046\n",
            "Epoch 963/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9165\n",
            "Epoch 964/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.9129\n",
            "Epoch 965/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.9023\n",
            "Epoch 966/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9094\n",
            "Epoch 967/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9111\n",
            "Epoch 968/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.9070\n",
            "Epoch 969/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9135\n",
            "Epoch 970/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9200\n",
            "Epoch 971/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9046\n",
            "Epoch 972/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9052\n",
            "Epoch 973/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9141\n",
            "Epoch 974/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9165\n",
            "Epoch 975/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9082\n",
            "Epoch 976/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9105\n",
            "Epoch 977/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9147\n",
            "Epoch 978/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9064\n",
            "Epoch 979/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9188\n",
            "Epoch 980/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9094\n",
            "Epoch 981/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9034\n",
            "Epoch 982/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.9052\n",
            "Epoch 983/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.9005\n",
            "Epoch 984/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9064\n",
            "Epoch 985/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9076\n",
            "Epoch 986/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9082\n",
            "Epoch 987/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9111\n",
            "Epoch 988/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.9058\n",
            "Epoch 989/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.9034\n",
            "Epoch 990/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8999\n",
            "Epoch 991/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9177\n",
            "Epoch 992/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8963\n",
            "Epoch 993/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9159\n",
            "Epoch 994/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.9094\n",
            "Epoch 995/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.9094\n",
            "Epoch 996/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9153\n",
            "Epoch 997/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9171\n",
            "Epoch 998/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9123\n",
            "Epoch 999/1000\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9028\n",
            "Epoch 1000/1000\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.9076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptado de: https://keras.io/visualization/\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(log.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(log.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "PsDadUcGixvk",
        "outputId": "44ff8b06-b224-4808-84e3-30a3d0eea44e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFNCAYAAABfWL0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU1fnH8c8zk8lKEiAJO2FH9kURRVzAFUWr1WrBXWuprVatVau1rtXqry5Vq9ZaS3GpWrXaasUNFVERARFF9lUJIDskQJZJ5vz+mMkw2SDbZDLh+369eDH33nPvfULt3Dz3nPMcc84hIiIiIiIiLZcn1gGIiIiIiIhIdCnxExERERERaeGU+ImIiIiIiLRwSvxERERERERaOCV+IiIiIiIiLZwSPxERERERkRZOiZ9IM2Vm3c3MmVlCLdpebGafNPQ6IiIiTaGxnnEiUntK/EQagZmtMbMSM8uutP/L0IOte2wiExERaRg940RaBiV+Io1nNTCxfMPMBgOpsQtHRESk0egZVw2NppF4osRPpPE8C1wYsX0R8ExkAzPLNLNnzGyzmX1rZr8zM0/omNfM7jezLWa2Chhfzbl/N7MNZrbOzO4yM29dgzSzTmb2upltM7MVZvbTiGMjzWyumeWb2UYzezC0P9nMnjOzrWa2w8zmmFn7ut5bRETiVrN9xpnZy2b2vZntNLMZZjYw4liKmT0QimenmX1iZimhY0ea2czQc22tmV0c2j/dzC6LuEaFoaahXs4rzGw5sDy07+HQNfLN7AszOyqivdfMfmtmK82sIHS8q5k9ZmYPVPpZXjezX9Xm5xapKyV+Io1nFpBhZv1DD6sJwHOV2vwZyAR6AscQfIheEjr2U+BUYDgwAvhRpXOnAKVA71CbE4HLqLsXgTygU+gefzCzY0PHHgYeds5lAL2Al0L7LwrF3RXIAi4HCutxbxERiU/N+Rn3FtAHaAfMA/4Zcex+4BDgCKAtcAMQMLNuofP+DOQAw4D5tbwfwBnAYcCA0Pac0DXaAs8DL5tZcujYtQR7S08BMoBLgT3A08DEiOQ4Gzg+dL5Io1PiJ9K4yt+IngAsBtaVH4h4UN7knCtwzq0BHgAuCDU5B3jIObfWObcNuCfi3PYEHxjXOOd2O+c2AX8KXa/WzKwrMBr4jXOuyDk3H3iKvW9x/UBvM8t2zu1yzs2K2J8F9HbOlTnnvnDO5dfl3iIiEvea5TPOOTc5dM9i4HZgaKgH0UMwybraObcu9PyaGWp3LjDNOfeCc87vnNsaeibW1j3OuW3OucJQDM+FrlHqnHsASAIOCrW9DPidc26pC/oq1HY2sBM4LtRuAjDdObexDnGI1JrGJYs0rmeBGUAPKg2BAbIBH/BtxL5vgc6hz52AtZWOlesWOneDmZXv81RqXxudgG3OuYJK9xkR+vwT4E5giZmtBu5wzv0v9HN1BV40s9YE3/Le7Jzz1/H+IiISv5rdMy6UcN4NnE2w5y4QEU8SkAysrObUrjXsr60KsZnZdQSfoZ0AR7Bnr7wYzr7u9TRwPvBe6O+HGxCTyD6px0+kETnnviU4Af4U4NVKh7cQ7DnrFrEvl71vTDcQfDhEHiu3FigGsp1zrUN/MpxzA6mb9UBbM0uvLgbn3HLn3ESCw2X+D3jFzNJCb0PvcM4NIDhc5lQqzvUQEZEWrpk+484FTic4RDIT6B7ab6GYighOXahsbQ37AXZTsXBNh2rauPIPofl8NxDs1WzjnGtNsCevPIvd172eA043s6FAf+A/NbQTaTAlfiKN7yfAsc653ZE7nXNlBOfM3W1m6aH5Bdeyd47ES8BVZtbFzNoAN0acuwF4F3jAzDLMzGNmvczsmLoE5pxbC8wE7gkVbBkSivc5ADM738xynHMBYEfotICZjTWzwaE3q/kEH+6Bam4hIiItW3N7xqUTTBq3EkzW/hBx3QAwGXgwVNjMa2ajzCyJ4DzA483sHDNLMLMsMxsWOnU+cKaZpZpZ79DPvL8YSoHNQIKZ3Uqwx6/cU8DvzayPBQ0xs6xQjHkE5wc+C/y7fOioSDQo8RNpZM65lc65uTUc/iXBN4mrgE8ITuCeHDr2N+Ad4CuCk9Mrv029EEgEFgHbgVeAjvUIcSLBN6LrgdeA25xz00LHxgELzWwXweEmE0IPoQ6h++UTnNfxEcGHlIiIHECa4TPuGYLDRteFzp1V6fh1wAKCydU2gqNZPM657wj2XP46tH8+MDR0zp+AEmAjwaGY/2Tf3gHeBpaFYimi4lDQBwkmvu8SfI7+HUiJOP40MBg9VyXKzDm3/1YiIiIiItLozOxogj2j3Zx+MZcoUo+fiIiIiEgMmJkPuBp4SkmfRJsSPxERERGRJmZm/QnOp+8IPBTjcOQAoKGeIiIiIiIiLZx6/ERERERERFo4JX4iIiIiIiItXEKsA2hM2dnZrnv37rEOQ0REouyLL77Y4pzLiXUc8ULPRxGRA0dNz8gWlfh1796duXNrWlpGRERaCjP7NtYxxBM9H0VEDhw1PSM11FNERERERKSFU+InIiIiIiLSwinxExERERERaeFa1By/6vj9fvLy8igqKop1KFGXnJxMly5d8Pl8sQ5FRESaOT0fRUQOLC0+8cvLyyM9PZ3u3btjZrEOJ2qcc2zdupW8vDx69OgR63BERKSZ0/NRROTA0uKHehYVFZGVldWiH2oAZkZWVtYB8eZWREQaTs9HEZEDS4tP/IAW/1Ard6D8nCIi0jgOlOfGgfJziojsywGR+MXK1q1bGTZsGMOGDaNDhw507tw5vF1SUrLPc+fOnctVV13VRJGKiIg0LT0jRUSaVouf4xdLWVlZzJ8/H4Dbb7+dVq1acd1114WPl5aWkpBQ/f8EI0aMYMSIEU0Sp4iISFPTM1JEpGmpxy/Cjj0l7Coujeo9Lr74Yi6//HIOO+wwbrjhBmbPns2oUaMYPnw4RxxxBEuXLgVg+vTpnHrqqUDwgXjppZcyZswYevbsySOPPBLVGEVERGJBz0gRaWmWfJ/Php2FsQ4DUI9fBRt2FtEqKYFWSdH9Z8nLy2PmzJl4vV7y8/P5+OOPSUhIYNq0afz2t7/l3//+d5VzlixZwocffkhBQQEHHXQQP//5z1WWWkREWhw9I0WkJdi6q5isVkmMe+hjkhI8zLzxWH772gKK/AGevnQkAIs35LN80y6O7pPN8k27OLR726jGdEAlfne8sZBF6/NrPL6npAyvx0hKqH1H6IBOGdx22sA6xXH22Wfj9XoB2LlzJxdddBHLly/HzPD7/dWeM378eJKSkkhKSqJdu3Zs3LiRLl261Om+IiIi1dnf87E+6vN8BD0jRaT5++/8dfTvmEHf9unVHv94+WYu+PtsHj/vYACKSwMccte0Ku1OfvjjCtsLbj+R9OTovbTSUM8YSEtLC3++5ZZbGDt2LN988w1vvPFGjeWmk5KSwp+9Xi+lpdEdkioiIhILekaKSFOZsWwzn6/ayrbdJfz1o5UEAq5Km+93FvHUx6vocdObdL/xTZ6d9S1XvzifE/80A4AnPlrJ/e8sxbm95/7x7eCw9F/8c16193XO8dXaHVX2L8jb2Rg/Vo0OqB6//b15XPJ9PqmJCeS2TW2iiIJvMzt37gzAlClTmuy+IiLSPJnZOOBhwAs85Zy7t9LxbsBkIAfYBpzvnMtryD3r0zPXFPSMFJFoWLQ+nzZpPi6cPBuA0b2z+HTFVnLSk+jXIYMVm3eRlZbIH99ewleVkrFb/vNN+HNZwHHvW0sAGNwlk/SkBHKzUlmwbt8J3LKNuzj9sU+r7J++bDOjekVvfdUDKvHbHwOomuhH1Q033MBFF13EXXfdxfjx45v25iIi0qyYmRd4DDgByAPmmNnrzrlFEc3uB55xzj1tZscC9wAXNH200adnpEjztKmgiPzCUnq3a9Uk93v9q/UM6JhO73bBoZXOOT5fvY0hXTJJTax9OrNjTwmtUxM55ZGKQyznfRvsfbv2pa/qFNdVL34Z/vyzZ7+o9XknPTSj2v1PzljFL8b0onVqYp3iqC2L7JaMdyNGjHBz586tsG/x4sX079+/Vucv/b6AFJ+X3Kym6/FrbHX5eUVE4pWZfeGca3H1/M1sFHC7c+6k0PZNAM65eyLaLATGOefWWvC18E7nXMa+rtvQ52NLcKD9vCLRdOjd09hcUMyae8cze/U2Du3eJmq9VCWlAfr+7i0A7jx9IBt2FvGX6SsBuO20AVwyugewd95dh8xkrnlxPqcP68SJAzpwzH0fMuHQrjzywQoAzj88l+dmfdeoMZ53WC7//Lz6a3ZuncK6HYU8deEInpn1LTOWba7S5mfH9OSvH60CYM29DX/JVdMzUj1+lbim7vITERHZqzOwNmI7DzisUpuvgDMJDgf9IZBuZlnOua1NE6KIHOg2FxQD8OLs77jx1QX0yknjv1ceyRtfrcdrxjmHdgWgoMhPerKPQMDx9GdrOGNYZ1ISvST7vNVed82W3ewqLuWTFVsY1CmT61/5ig07987tfWjacrbtLglv3/HGItqmJfLwtOWs2rKbZJ+HS0f34IMlm/hgySauPq4PmwqKw0kf0OhJ3y/G9OJXJ/StkvgN7JTBwvX5vPOro1m9eTeDu2RybL929PztVABuPqU/d09dDIBhnHVwF7JaRaenr5wSvwjReU8hIiLSqK4DHjWzi4EZwDqgrHIjM5sETALIzc1tyvhEJE4EAo7i0gA3vfo1HjMe/PGw8LEifxkJHsPrMa5/5WumL93MY+cOp3v23gJM05cGe69Wbt7N3W8u5oXZweTnnEO78uHSTVzyjzlcObY3L875ji27SrjjjUV0yEjm49+M5bQ/f0J2qyQ+X70Vf5ljzs3HM+b+6fuM1+up+tv61S/Oj4g5wOOh3kCAh99fXut/i3EDO/D2wu8r7HvtF0fww8dnVtg39aqjOO+pWQzqnMnHy7dwdN8cfF4PL18+irOf+AyA343vzyWje+AvC5Ds8zK4SyYAHo/x8Q1jeeT95VwwqtvexM/ggXOG1jrW+lLiF0mZn4iIxNY6oGvEdpfQvjDn3HqCPX6YWSvgLOdclfJwzrkngSchONQzWgGLSNNyzrGnpIy0GtadPueJzxjTL4eBnTJpm5oYTjoACkvKSErw4AklUHe9uZjJn64OH49M/Prd8jYAL/z0cF75Ilg/6q1vvuetbzaE22zbs7f37b1FFZOmWSuDgxAe/XBFhf3f5xcx9I532VNSBhSE99/2+jfsT3lPY3VuO20Ad7yxqMbjNRnUOYNv1uVz9ogu4cTvw+vGUFoWoE/Ecg0/ObIH3bJSGdApgy9vPZFAwLGpoJgOmckAHNq9LbNuOg5/WYCuoUKRXk/Vns2ubVO57+xgkvevSYfz4ydncUSvrDrHXR8HROLnnKv1uON4nvLYkuZriogcoOYAfcysB8GEbwJwbmQDM8sGtjnnAsBNBCt81ktdno/xTM9HaSlmrtjCuU99TnpyAl/deiJrtu5mysw13HbaQLwewznH7DXbmL1mW/icNfeOp7CkjO17Sjji3g8YP6Qjxf4ypi3eVOX636zbyavz1lHo3zuIYOLfZu29/8otbMzfm3yt2bI7/HnLrr1JoL8sQFk1SyOUCyZ9FU1d8H01Lfc6qH06SzcGE8WJI3PDvYvlLhndI5z4nXtYLs9XGno5cWRXXpgdHEk/+eIRXDolOO+5/OuhbdreYZY9Ino1y91y6oAK2x6PhZO+cpW39+ewnlksvOOkGpP4xtbiE7/k5GS2bt1KVlb0SqM2B845tm7dSnJy3f6DExGR5sM5V2pmVwLvEFzOYbJzbqGZ3QnMdc69DowB7jEzR3Co5xX1uZeejyLN2wuzv2NPSRk/ObJHeN+5T30OQEFRKRsLivj5c/NYurGAZJ+X357Sn/yiqmtYjrhrGlt27U3W3vx6Q5U25U798yc1Hrvm+D48NK3i0MlNoR64zBQfOwv94f2nP/opizbkA8EkanVEgliuR3YaZ4/owvodhQzslMlNry6o8d43n9K/Qs/k5cf0rJL4Rbr11AH0yEqjS5sUHpu+gm/W5XPREd05aWAHvvxuB2MParc31mGdWLg+n86tU7hibC+++HZ7jdeNhqZK+uAASPy6dOlCXl4emzdXraBT2ab8Irweo3Bz0n7bNkfJycl06dIl1mGIiEgDOOemAlMr7bs14vMrwCsNvU9dno/xTs9HaSzXv/wVvgQPf/jh4Kjdo8hfxh1vLAonNs45Nu8q5vzDulVotzpUCAWCywBccHi38HakyKSvIQZ3zqx2f8+cNN771TEUFPl5cc5a7n1rSTjpA3jvV0fT93dvEXDBBG78kI6c+fhMbjq5HycO7ADAhp2FJCV4KAs4SqvpKUxN8rIxf2+Rl7SkBK4+rk+VOXz/vOwwPlmxhWSfl58e3ROA4we0Z9632+nXIYN+HTIYE5H0Afz0qJ5MHJlLerKP60/qV+XeM64fS4K3Zbwca/HLOdTFaX/+hJz0JCZffGgjRiUiIo2tpS7nEC0NfT6KSFD3G98E9pbcLy4t4+W5eUw4tCsJXk+Ftm9/s4Etu0o4//CKCVtpWYA73ljE9/lFtE7x8X9nDcEfCJCU4KXIX8YFf/+cOWv23+uUlOChuDTQSD9ZRYd2b1MlhjevOpLxj1TfI1j+77F+RyFH3PtBlWNrtuxm3nfbOfPgfb+AueONhfzj0zXkpCdVmM/3wNlDaZ+RzPl/D/Z4Lvn9OJISPOzY42fsA9P5zbh+TBxZtyJWHy7dROsUH8Nz29TpvHig5RxqwWMQaEGJsIiIiIg03Gcrt1aYA1bu4WnLeXz6SjJTfJw2tFN4/6aCIi5/bh4APq8xfkgn7n5zMdefdBDrdxTy7Kxvw23TkhKYMnMNC24/kXvfWrLfpO/CUd145rNv95v0Dc9tzZffBes+9euQTpc2qWSm+Pj3vDx65aTx+pVH8sxn33Le4bm4AGzeVcTxDwYXFn/58iPYvrsEjxkfLN3I4T2zSIxIbB/68TCu+VewmuYVY3uF93dqnVIhhnNGBBO97tlpFaqB1uTEAR34x6dr+NnRPbnrzcXh/R4PHNknmzOGdeI/89eTlODBzGiTlsj8W0/c73WrM7ZSz9+BQIlfBDNjH/NQRURERKSFyNu+hwsnz+bpS0bStW0qm/KLMDNy0qtO+YkscAJQFnD4ywLMCRVR2bqrmDVbdpOY4CExwcPIu98Pt/3Nvxfwv6838PHyLWwuKCIjxVfhWlNmrgHg8D+8z+5qip5U1j5j3/NVyxcM79Q6hQ07ivg+v4inLhpBlzapbMwvotBfyv+dNYS0pAR+PmZv0lbe+ZHsCyZ4bUKJ7g+H7+2l83kNf5kjNXFvtcrrTjyowv3bpSexs9DP7JuPJy2x+vX6ajKqVxbzbjkB51yFxM9CpffvP3sod54xqEXPS44mJX4RzFT5S0RERCRe7dhTwp6SsnDP04adhaT4vLROrdpb9+ysb1m1eTcvzvmO3cVl4QSsc+sU/nDmYI7pm8OeklL+MHVxlXN7/bbCNFxuf2MRhCpK+qqZD/bx8i0A1VbSLLe7pIyj++YwY9neebenDunIoM6ZPDRtGUX+YA9fUsLenrdHJg7nqhe+pHPrFP587nB6Zqfx7qKN3PDK1yR6PfztwhE889kaOmUG/z3aZyTz+HmHVHv/1qk+Jo7M5UeH1Dwc85BubZi1ahupiQn875dHsmrL7ipJ2EfXjyXgXL2LlpT3rL5y+Sj+Mn0l7y/ZRPktErweMioNqZXaU+IXwWOmoZ4iIiIicWDdjkJSfd5wzxTAmPuns2OPnzX3jueKf87jzQUbyEzxMefm4znvqVmcf3g3Vm/ZzfH927N22x4A5qzeXmH5g3U7Crlo8mwePGcoqzbv5rlZNVePrI6/rP6/Sz527nDW7yji8ekr+O/89dz9w8FkpvhI8Fi4ByxymYSeoeGT157Ql4NDc9X8ZcEEMdHrYXCXzPCacftjZtxzZu2K1pjBoM6ZDKqm4EtKHXv5ajKie1suO8rx/pJNHNq9baNc80CnxC+Cx+J7HT8RERGRliByjUnnHAEHXo9VOD763g/ISkvki1tOCO/fsSe4pEAg4HhzQXDZgp2Fft5Z+D1z1mwPz597aNpyMkNDLtftKKw2hmtf+qpWsd5y6gB+/7+qC4f/6JAu4YXPa/LD4Z157ct1ABzWoy3pyT4O6uDjwXOGccupA8IxXjK6By/PzWPpxoIK05Jy0pPChVXK+UNz/3wJ0RsO2VS/L4/qlVXl55P6U19pBFOPn4iIiEjUrdhUQKBSYYVZq7Zy71tL+GT5Fvr+7i0unTKHQMAx6dkvOOa+Dyu0LV9rbevuEmau3MLVL35ZIYFbuD6/QvtfvvBllRjK152rKfGL1Kddq2r3/2ZcPy4d3Z3fjAsuA/D8ZYeFj/32lP41Xq9nThrXn3QQ9/1oSLDq5b3j+dfPRoWPez1GdqukCttj+uUAFQsRtqpmOOVRfYPt9ldBsz7uOmMwx/dvz4juLa8S5oFAyzlEmPDkZwQcvBTxfzwREWl+tJxD3Wg5B2lO5q/dwRmPfcqtpw7g0ojFycuXSqjJY+cezPghHbnhla94ae6+e9Jqq/Li4mcM68Q5h3bl3L99XqHdqj+cwrJNBSR4LFz5EmDB7SeSnlyxWMt7izZiBNePm716G+f89TMGdMzg9GGduOetJQBVfvbamLZoI5c9M5dnLh2Jz+vh1Xl5/PFHQ1ToRKqo6RmpHr8IHjMVdxERERFpZGu37eFHf5nJll3FLFi3E4C3F37P+Ec+5tgHptfqGlc8P4/uN74ZTvpGdKt7r9Ptpw2osH3RqIpr7P3px8M4olc2Q7u2Du/LbZuKx2P065BB73bpLPn9uPCxykkfwAkD2nP8gPYAjOzRlnm3nMBrVxzBSaHFyh89dziXjO5e59iPH9CeWTcdx9F9cxjVK4v7zh6qpE/qJGpz/MxsMnAqsMk5N6ia49cD50XE0R/Icc5tM7M1QAFQBpQ21VtdM7Scg4iIiEg9Oed4eW4eU2au4d6zBjOkSzCBevSDFcz9djtvfLU+PMRy9uq9BVXK6vELWPfsNOaGhnyOH9yRNxdsID05gR+P6MpTn6zm0tE9OLpvNr1yWrGpoIhZq7Zx0RHduXh0D+au2cbKzbs4fVhntuwqodBfRm7b1HAitSm/CIA/njWEcw7tWuG+yT4v7TOS2JhfTG2UV6nsnp3W4PlqHTL3vZSDyL5Es7jLFOBR4JnqDjrn7gPuAzCz04BfOee2RTQZ65zbEsX4qlBVTxERETnQPfbhCkpKA/zqhL4A7CkpZVdRKe0yksNFVyKLr0SavnQzN/z7awB+8Oin/O3CEVz7r/kUFJcCUOgv492FG6ucd9Hk2XWO0+f18Oi5w0lP9nFwbmveXLCBHw7vHO6Fy22bwpjQIt1d26ZySLe9lSFHdG/LiFClyOtOOqjKtcf2a8fzn3/HqF5Z1d77/V+PoawB1TtFYiFqiZ9zboaZda9l84nAC9GKpbaCX2SxjkJERESkcZSUBvjTtGX8fEwvMkIJUZG/jOlLNzNuUIcKbcfeP52cVknhpQ1G985mZI+2THhyFl/n7aR3u1as2LSLe88czI2vLuC6E/uyp6SM1qk+vvh2O87Bu4sqJnU/fabi3NI/vr202jg/WVH9u/7RvbMY0DGD34zrh9djPPrBCh54bxkQXC/v1CGdwm0/u+lYslslUVIaoLi0jAkjc+vwL1XRzaf059cn9CWrVdXF3KH6oioizV3M/6s1s1RgHHBlxG4HvGtmDvirc+7JpojFowXcRUREpAV5/av1/GX6Sor8Zdx22kDWbtvDHW8sZNriTbxy+SjaZyTz3OffcuxB7Vi9ZXeFQifn/PUzslslsWVXcEjjik27ALjx1QUA3P/usqjE7ImYenPHDwbRO6Ki5smDO0QkfhVLVXQMLVLu83q4IVRls77SkhLqvQC5SHPVHP6LPg34tNIwzyOdc+vMrB3wnpktcc7NqO5kM5sETALIza3/mx0oH+rZoEuIiIiIxIxzjqtfnM/ZI7pwVJ+c8GLeu4tL2VxQzFF/3Lsswn3vLOXz0Dy7v360qtrrlSd9DXXLqQM4dUhH7n9nKYf1zCIxwcNVoSUWbj6lP3dPDS5Ovube8ZQFHCPvnsbW3SVV5rT1bpfOW1cfxckPf8wpgzs2SmwiB4rmkPhNoNIwT+fcutDfm8zsNWAkUG3iF+oNfBKC5aobEkjwDZMyPxEREYkfs1dvY/Inq7nltAEkJ3h4/av1vP7VetbcO57yNc/LArBsY0GF8z5fva2aq9Vfss9DkT9QZf/8W0+gdWqwwMl9Zw8N7/d5jMQED8f1b0+Rv4xj+wfn43k9xguTDuejpZurHVLZv2OGFvUWqYeYJn5mlgkcA5wfsS8N8DjnCkKfTwTubKKI1OMnIiIizdamgiLapCays9BPYoKHktIAv/jnF2zZVcLbC7+v0HbLruJwBc1/z8vj3/P2vfbd9ScdxBVjewPw/uKN/OTpivPzhue25svvdoS3H5k4PNxr969Jh3NYzyy++HY7bdMS6ZGdxo49JQQc4aSvspMjeux+eVyfCsf6tk+nb/v0fcYrInUTzeUcXgDGANlmlgfcBvgAnHNPhJr9EHjXObc74tT2wGuhSlEJwPPOubejFWckzfETERGRWNuyq5j05ASSErwV9vvLAoy8+31+OLwzM1duCS8n0D6j+gIkI+6aVqf7lpTu7a2rnHS9+6uj6dOuFT1umgrA29ccRb8OGaT6vAzpmkm79OCQzEMi1tarKeETkdiIZlXPibVoM4Xgsg+R+1YBQ6trH20eVfUUERGRGFqxaRfHP/gRx/dvx/H92zNhZC479/jxeo3CkjIAXvtyXYVzarue3LiBHeiWnUpaYgIPhgqk9MhOCxd0Gd07O9y2fcbeuXU+r4UTwTk3H0+i10NmarBCaPlC5SLS/DWHOX7NhsejOX4iIiLSdNbvKOStb77n0tHdMTOWfh+chzdt8SamLd7EN+t38tys72p1rVOHdOR/X2+osK9dehIvXz6qwuLkAOOHdOSXz3/Jsz8ZydQFG+jVrhUjex27uD4AACAASURBVOxd5y4xwcPHN4zltS/XMTa0Fh5ATnr1vYsi0vwp8YtgWsBdREREmtBlT89l0YZ8xg/uSIfMZPKL/BWO7y/pi+yxe/Tcg3noxwGWbixg/COfAPD0pSPplpVW5bxeOa2YevVRAFwwqnu11+7aNpWrKs29E5H45dl/kwOHhnqKiIhIY/p0xRY+Xr4Z5xybCoqqHF+0IR+Aw+95nxMe/IgPl2yq0/VPGlhxEfYEr4estL29cv07ZtQjahFpiZT4RTA01FNEREQaz3lPfc4Ff5/N9GWbGXn3+7z59QZ27vFTUOTnrL/MrNB2+aZdvLtoY3i7U2YyXo9VaNO5dUqF7fLDyb69v9K1Ds2/ExGJpKGeETwGSvtERESkIUrLAuwuKSMzZW8CNju0Zt4Vz8+r9XVOGdyR1EQvj3ywgpk3HkuCx8hJT6LHTVPJSU9ic0Ex/Tpm8NlNx1aoAJrs8zI8tzXnHdat8X4oEYl7SvwieDTHT0RERBrolv8u5IXZ35GYsLcX7i/TV1bb9tFzh3Pl81+GE7lyd50xiB8d0oWkBA9XHdeHBO/ea624+2Q8ZizakM/AThkViraUe+0XoxvxJxKRlkCJXwQzIxDYfzsRERGRSIGA47NVW1m3vZAXZgcLskSui1dZn3atuOq4PozuFVxC4fJjetEm1cfBuW3o2ja1whDPBG/FxK48CRzUObOxfwwRacGU+EXQAu4iIhJrZjYOeBjwAk855+6tdDwXeBpoHWpzo3NuapMHKhX8/ZPV3D11ca3bv3ftMeHPy+46GZ/Xqu25ExFpLCruEiE41DPWUYiIyIHKzLzAY8DJwABgopkNqNTsd8BLzrnhwATg8aaNUgIBx+7iUgBuf30h1740n09XbqnS7pZT9/5P99CPh3Ha0E4ADOxUsdJmYoJHSZ+IRJ16/CKYqaqniIjE1EhghXNuFYCZvQicDiyKaOOA8swhE1jfpBEewKYu2EC3rFRe+SKPf3y6hl8d35cpM9cAkJRQ8V36UxeOwBsaonlEryzOGN6ZM4Z35urj+mgRdBGJCSV+EcxMVT1FRCSWOgNrI7bzgMMqtbkdeNfMfgmkAcc3TWgHNuccv/hnxYqcf5q2LPy5uNJ8vuMHtKegyE92qyR+MaZ3eH/vdq2iG6iISA2U+EXQHD8REYkDE4EpzrkHzGwU8KyZDXLOVcg8zGwSMAkgNzc3BmHGv7KA4+g/fsi6HYX8+oS+dT4/PdnH3N8pLxeR5kFz/CJojp+IiMTYOqBrxHaX0L5IPwFeAnDOfQYkA9mVL+Sce9I5N8I5NyInJydK4bZsW3cXs25HIQAPvLesxnaH9WiLGcy75QQAOmYmN0l8IiJ1oR6/CB7N8RMRkdiaA/Qxsx4EE74JwLmV2nwHHAdMMbP+BBO/zU0aZQu2p6SUL7/bwctz13Joj7b7bZ+VlsizPzmMsoAjJdHLtGuPpk1qYhNEKiJSN0r8IgTX8VPiJyIiseGcKzWzK4F3CC7VMNk5t9DM7gTmOudeB34N/M3MfkWw0MvFTvMUGs01L87n3UUbAfjP/Orr5hzbrx1H9s7m1KEdyUj2VViovXe79CaJU0SkrpT4RTADPTpFRCSWQmvyTa2079aIz4uA0U0dV0u1fXcJZ/5lJsf2a8fEkbl8tnJrjW17t2vFik27aJuWyKVH9mjCKEVEGk6JXwSPqnqKiIgcUB5+fzmrt+zm75+s5u+frMZTw3J6/5p0OAM6ZXDjqwu4YdxBTRukiEgjUOIXQXP8REREDizlC7GXK5/xYQY3n9Kfsw/pyvOzv2NE97Z4PcZj5x4cgyhFRBpOiV8EjxllmuMnIiJywPCXBard/8lvjqVz6xQAfj6mV1OGJCISFVrOIUKCV4mfiIhIS7P0+4Iq+7buKmZTflG1BVzuP3toOOkTEWkp1OMXwef1UBpwBAIOT02D/EVERCRuvPn1Bq54fh5PnH8I4wZ1AGDed9s58/GZVdr+8tje9G7XitOHdW7qMEVEok6JXwSfN9gB6g8ESPJ4YxyNiIiINNSiDTsBWL6xgHGDOuAvC3DR5NlV2o05KIdfn6iiLSLScinxi5BYnviVOZL0LyMiIhK3ivxlvLPwe8qn8Hk8xu2vL2TKzDVV2j5x/iGM7ZfTtAGKiDQxpTcRfN7g8E5/aQCSYhyMiIiI1Mvb33zP5c99UWHfB0s28cW326ttf3jPtiQlaKSPiLRsSvwi+BLKe/yqr/AlIiIizUthSRk7C/10yEzmhdnf8f7ijSzeULWYS+Wkb3TvLO48fRAFRaW0Tk1sqnBFRGJGiV+E8jl+JUr8RERE4sIlU2Yza9U2Prp+DDe9umC/7f/3yyNZv6OQ0b2zSdO8DhE5gOgbL0LkHD8RERFpni57eg7z1+7kllP7M2vVNgCOuW/6fs97cdLhDOqcyaDOmVGOUESk+dE6fhESNdRTRESk2Zu2eBNbdhVz9Yvzqz3+4DlDK2xPHJnLg+cM5fCeWU0RnohIsxS1Hj8zmwycCmxyzg2q5vgY4L/A6tCuV51zd4aOjQMeBrzAU865e6MVZ6TwUM9SJX4iIiLNUSBQ86icP/14KGcM64yZkV/o5/Y3FgFwz5mDmyo8EZFmK5o9flOAcftp87FzbljoT3nS5wUeA04GBgATzWxAFOMMC1f1VI+fiIhIs7BsYwF//WglZQHHzkI/E/82K3xs3MAOFdqO6NYWs+Cz/OLRPZo0ThGR5i5qPX7OuRlm1r0ep44EVjjnVgGY2YvA6cCixouueprjJyIiEnvOOdbtKGRTQTFnPj4TgKQET7gHD2BgpwwemjCMnYV+DvvD+wBkt6q4FtOJA9rz2cqtTRe4iEgzFuviLqPM7CtgPXCdc24h0BlYG9EmDzisKYLRcg4iIiKxM3PFFgZ3yWTOmm1cOmVuhWORSd9ZB3fhgdA8vmSflyfOP5gX56wlJbHiWnxPXjgi+kGLiMSJWCZ+84BuzrldZnYK8B+gT10vYmaTgEkAubm5DQpIyzmIiIjExsb8Is596nPGDezAId3a7LPtdSf1rbA9blBHxg3qGM3wRETiXsyqejrn8p1zu0KfpwI+M8sG1gFdI5p2Ce2r6TpPOudGOOdG5OTkNCim8jl+xX4lfiIiIk1pxx4/ACs272LzruLw/qP6ZHPB4d3C262SEuiYmdLk8YmIxLuY9fiZWQdgo3POmdlIgknoVmAH0MfMehBM+CYA5zZFTCm+4BCR4tKypridiIiIhBQU+cN/z1y5Jbz/mUtHYmY8O+tbAJ6+9NCYxCciEu+iuZzDC8AYINvM8oDbAB+Ac+4J4EfAz82sFCgEJjjnHFBqZlcC7xBczmFyaO5f1JXPDSjyK/ETERFpSttDPX4b84vZmF+M12PcfEr/cJXOB84eSqvkBA7p1jaWYYqIxK1oVvWcuJ/jjwKP1nBsKjA1GnHtS3JCMPErLFHiJyIi0lQ+WLKRN75aX2HfvyYdzojue5O8sw7p0tRhiYi0KLGu6tmslPf4FWqOn4iISJOpXMHzd+P7V0j6RESk4WJW3KU5Sgot56ChniIiItHlLwvwxEcr2VNSWuXYZUf1jEFEIiItm3r8IpgZyT6PEj8REZEo63PzWwAsXJ8f40hERA4M6vGrJNnnpVCJn4iISNREvmCtPLdPRESiQz1+laT4vOrxExGRmDGzccDDBCtbP+Wcu7fS8T8BY0ObqUA751zrpo2yYb7btqfKvn9cfCht0xIpKdM8exGRaFDiV0mKz6viLiIiEhNm5gUeA04A8oA5Zva6c25ReRvn3K8i2v8SGN7kgTbAso0FnPinGVX256QnMahzZgwiEhE5MGioZyVJ6vETEZHYGQmscM6tcs6VAC8Cp++j/UTghSaJrJH84p/zqt2fmeJr4khERA4sSvwqSVFxFxERiZ3OwNqI7bzQvirMrBvQA/igCeJqNJsLisOf19w7Hk9wfXbSkzUISUQkmpT4VZLs82oBdxERiQcTgFecc9U+tMxskpnNNbO5mzdvbuLQqjd79TZ2Fvo5qH060649GoALR3UHoFWSEj8RkWhS4ldJis9LUakSPxERiYl1QNeI7S6hfdWZwD6GeTrnnnTOjXDOjcjJyWnEEOuuuLSMaYs2cs5fPwPg4tHd6d0uHYBbTx3AojtPIsGrX0lERKJJr9cqSU5Uj5+IiMTMHKCPmfUgmPBNAM6t3MjM+gFtgM+aNrz6uWfqEqbMXBPebpOaGP7s8Ripifp1REQk2vR6rZLkBC9FquopIiIx4JwrBa4E3gEWAy855xaa2Z1m9oOIphOAF51zLhZx1tVXeTsqbJvFKBARkQOYXrFVkpKo4i4iIhI7zrmpwNRK+26ttH17U8bUUGmVevSGd42rZQdFRFoEJX6VJCd4KVTiJyIi0mDOOUoDLrxUwyMTh/ODoZ1iHJWIyIFJiV8lKYnBdfycc5jGooiIiNTb/e8u5bEPV4a3lfSJiMSO5vhVkuzzEnBQUqZ5fiIiIvUVCLgKSV//jhkxjEZERJT4VZLs8wJQVKLET0REpL56/nbvNEWf13jl8lExjEZERJT4VZJSnvhpLT8REZF6iSySNqBjBlMuGUmaFmgXEYkpJX6VJPuC/yRay09ERKR+/u/tJeHP1590EKN7Z8cwGhERASV+VZT3+Kmyp4iISN055/jHp2vC2znpSbELRkREwpT4VZKcGBrqqcRPRESkzvKLSitsZ7dS4ici0hwo8askOUE9fiIiIvW1Kb+ownZWq8QYRSIiIpE007qSlFCPX7FfVT1FRETqwl8W4PdvLgbgnjMH4y8L4PPqHbOISHOgxK+ScHEX9fiJiIjUyd8+XsWMZZsBmHBoV8wsxhGJiEg5vYarJFzcRVU9RURE6mTd9sLwZyV9IiLNixK/SrSOn4iISP14PUr2RESaKw31rCRJPX4iIiJ14pzjlv9+w3OzvgPgsiN7xDgiERGpTIlfJeEeP83xExERqZW12wrDSd/1Jx3EFWN7xzgiERGpLGpDPc1sspltMrNvajh+npl9bWYLzGymmQ2NOLYmtH++mc2NVozV8XkNj0GRqnqKiIjs13/nr+Po+z4Mb//8mF4xjEZERGoSzTl+U4Bx+zi+GjjGOTcY+D3wZKXjY51zw5xzI6IUX7XMjBSfV1U9RUREauHJGasqbHs0z09EpFmK2lBP59wMM+u+j+MzIzZnAV2iFUtdJSvxExERqZXk0BQJgH///IgYRiIiIvvSXKp6/gR4K2LbAe+a2RdmNqmpg0n2eTXHT0REpBbK17/tkJHMId3axDgaERGpScyLu5jZWIKJ35ERu490zq0zs3bAe2a2xDk3o4bzJwGTAHJzcxslppREJX4iIiK1kZQQ7PEb2y8nxpGIiMi+xLTHz8yGAE8Bpzvntpbvd86tC/29CXgNGFnTNZxzTzrnRjjnRuTkNM5DJzXRy+5iJX4iIiL74/MaCR7jjh8MinUoIiKyDzFL/MwsF3gVuMA5tyxif5qZpZd/Bk4Eqq0MGi2ZKT52Fvqb8pYiIiJxaVdxKcO6tiYxobnMHhERkepEbainmb0AjAGyzSwPuA3wATjnngBuBbKAx80MoDRUwbM98FpoXwLwvHPu7WjFWZ2MFB/rthc25S1FRETi0qb8Ynpkp8U6DBER2Y9oVvWcuJ/jlwGXVbN/FTC06hlNRz1+IiLSEGZ2GvCmc65FLwq7dtselm/axZF9smMdioiI7IfGZVSjdYqPHYV+nHOxDkVEROLTj4HlZvZHM+sX62AaWyDgmPzJaq54fh4AaYkxrxUnIiL7ocSvGpkpPsoCjt0lKvAiIiJ155w7HxgOrASmmNlnZjapfA77vpjZODNbamYrzOzGGtqcY2aLzGyhmT3fyOHv1/tLNnHn/xbxdd5OAC4Z3b2pQxARkTpS4leNzBQfgIZ7iohIvTnn8oFXgBeBjsAPgXlm9suazjEzL/AYcDIwAJhoZgMqtekD3ASMds4NBK6Jzk9Qs7LA3hGsFxzejaxWSU0dgoiI1JESv2qEE789SvxERKTuzOwHZvYaMJ1gYbORzrmTCc5h//U+Th0JrHDOrXLOlRBMGk+v1OanwGPOue0QXvqoSZWv3QfQLl1Jn4hIPNCg/GpkpgYTvx2FJTGORERE4tRZwJ+cczMidzrn9pjZT/ZxXmdgbcR2HnBYpTZ9AczsU8AL3N7U1a/9ZXt7/HKU+ImIxAUlftUo7/HL11BPERGpn9uBDeUbZpYCtHfOrXHOvd/AaycAfQgumdQFmGFmg51zOyIbmdkkYBJAbm5uA29Z0Y6I52Of9vudtigiIs2AhnpWo3VqIgA7NNRTRETq52UgcimHstC+/VkHdI3Y7hLaFykPeN0553fOrQaWEUwEK3DOPemcG+GcG5GTk1On4Pfly++2c8MrX4e3B3bKaLRri4hI9Cjxq0ZWWjDx27KrOMaRiIhInEoIzdEDIPQ5sRbnzQH6mFkPM0sEJgCvV2rzH4K9fZhZNsGhn6saI+jamLlya/jz+78+hmSfdx+tRUSkuVDiV41kn5f05AS27NIcPxERqZfNZvaD8g0zOx3Ysr+TnHOlwJXAO8Bi4CXn3EIzuzPieu8AW81sEfAhcL1zbmv1V2x8JaV7OzI7ZiY31W1FRKSBNMevBjnpSWwuUI+fiIjUy+XAP83sUcAIFmy5sDYnOuemAlMr7bs14rMDrg39aXK7i0vDn5MT1NsnIhIvlPjVILtVEps11FNEROrBObcSONzMWoW2d8U4pEZTUBRM/Lwew+OxGEcjIiK1VavEz8zSgELnXMDM+gL9gLeccy22+klOehKL1+fHOgwREYlTZjYeGAgkmwUTJOfcnTENqhHsKiklKy2Rt685OtahiIhIHdR2jt8Mgg+uzsC7wAXAlGgF1RzktNJQTxERqR8zewL4MfBLgkM9zwa6xTSoRrK7uJTObVK0fp+ISJypbeJnzrk9wJnA4865swm+xWyxctKTKCgupchfFutQREQk/hzhnLsQ2O6cuwMYRWjh9Xi3p7iMtETNFBERiTe1TvzMbBRwHvBmaF+LntGd0yr4JlO9fiIiUg9Fob/3mFknwA90jGE8jWZXcSlpSS36VwARkRaptonfNcBNwGuhstI9CZaQbrHKh7CowIuIiNTDG2bWGrgPmAesAZ6PaUSNZPueEtKS1OMnIhJvavXN7Zz7CPgIwMw8wBbn3FXRDCzWskM9flvU4yciInUQek6+75zbAfzbzP4HJDvndsY4tAZb+n0BG3YWkejVMsAiIvGmVt/cZva8mWWEqnt+Aywys+ujG1psqcdPRETqwzkXAB6L2C5uCUkfwMrNwVUpxg3qEONIRESkrmr7ym6Acy4fOAN4C+hBsLJni5XVKhHQHD8REamX983sLCtfx6GF2L6nBICBnTJjHImIiNRVbRM/n5n5CCZ+r4fW73PRCyv2fF4PbVJ9bFGPn4iI1N3PgJeBYjPLN7MCM4v7xWF37Aku39s61RfjSEREpK5qOzv7rwQnpn8FzDCzbkDcP8D2Jydda/mJiEjdOefSYx1DNGzfXUKKz0uyT1U9RUTiTW2LuzwCPBKx61szGxudkJqP9hnJ5G0vjHUYIiISZ8zs6Or2O+dmNHUsjSm/yE9Giip6iojEo1p9e5tZJnAbUP4g+wi4E2gRk9VrMrxrax79cAUFRX7SkzWsRUREai2yAFoyMBL4Ajg2NuE0Dn+ZIzFBFT1FROJRbb+9JwMFwDmhP/nAP6IVVHPRr2MGAYd6/UREpE6cc6dF/DkBGARsj3VcDeUvC+DzKPETEYlHtR2v0cs5d1bE9h1mNj8aATUn4SUdCorp3zHGwYiISDzLA/rHOoiG8pcF8GkNPxGRuFTbxK/QzI50zn0CYGajgRbfDRZexF2VPUVEpA7M7M/srX7tAYYB82IXUePwlzl8CS1qhQoRkQNGbRO/y4FnQnP9IDhc5aLohNR8lPf4aainiIjU0dyIz6XAC865T2MVTGPxlwVI0FBPEZG4VNuqnl8BQ80sI7Sdb2bXAF9HM7hYa5WUwICOGXy6YgtXHdcn1uGIiEj8eAUocs6VAZiZ18xSnXN7YhxXg/jLAiRqqKeISFyq07e3cy7fOVe+ft+1UYin2RncOZNVW3bHOgwREYkv7wMpEdspwLQYxdJoSjXUU0QkbjXktd1+v/nNbLKZbTKzb2o4bmb2iJmtMLOvzezgiGMXmdny0J+YDSvt3CaFzQXFFPnLYhWCiIjEn2Tn3K7yjdDn1BjG0yg01FNEJH415Nvb7b8JU4Bx+zh+MtAn9GcS8BcAM2tLcN3AwwiufXSbmbVpQKz11qVN8IVt3va4Hp0jIiJNa3ell5mH0AKKopWUOVX1FBGJU/uc42dmBVSf4BkVh7BUyzk3w8y676PJ6cAzzjkHzDKz1mbWERgDvOec2xaK4z2CCeQL+7tnY+vXIQOAhevz6d0uvalvLyIi8eka4GUzW0/wmdkB+HFsQ2q40rIAiRrqKSISl/aZ+Dnnop3pdAbWRmznhfbVtL8KM5tEsLeQ3NzcRg+wb/tWJCV4+DpvJ6cPqzYEERGRCpxzc8ysH3BQaNdS55w/ljE1Bg31FBGJX3H/7e2ce9I5N8I5NyInJ6fRr5/g9TCwUwZf5+1o9GuLiEjLZGZXAGnOuW+cc98ArczsF7GOq6H8GuopIhK3Yv3tvQ7oGrHdJbSvpv0x0a9jBss27tp/QxERkaCfOufCbwydc9uBn8Ywnkbh11BPEZG4FevE73XgwlB1z8OBnc65DcA7wIlm1iZU1OXE0L6Y6JGVxs5CP9t3l8QqBBERiS9eMwtnSGbmBRJrc6KZjTOzpaGK1zdWc/xiM9tsZvNDfy5rxLj3SUM9RUTiV60WcK8vM3uBYKGWbDPLI1ip0wfgnHsCmAqcAqwA9gCXhI5tM7PfA3NCl7qzvNBLLHTPTgNg9dbdtEmr1XNbREQObG8D/zKzv4a2fwa8tb+TQgniY8AJBOe3zzGz151ziyo1/Zdz7srGDLg2NNRTRCR+RTXxc85N3M9xB1xRw7HJwORoxFVXPbKDSy+t2bKbg3NjsqqEiIjEl98QLDx2eWj7a4KVPfdnJLDCObcKwMxeJFgBu3LiFxP+sgA+r4Z6iojEI722q4WubVPxGPxrztr9NxYRkQOecy4AfA6sIZjMHQssrsWpta1qfZaZfW1mr5hZ12qOR0Uw8dOvDiIi8Ujf3rWQlOBl7EHtmPvtdor8ZbEOR0REmikz62tmt5nZEuDPwHcAzrmxzrlHG+k2bwDdnXNDgPeAp2uIZZKZzTWzuZs3b27wTcsCjoBDiZ+ISJzSt3ctnT2iK2UBx+IN+bEORUREmq8lBHv3TnXOHemc+zNQlzeG+61q7Zzb6pwrDm0+BRxS3YUae7kjf1kAgAQN9RQRiUtK/GppcJdMAL5ZtzPGkYiISDN2JrAB+NDM/mZmxwF1yZTmAH3MrIeZJQITCFbADjOzjhGbP6B2Q0gbrDzxS1SPn4hIXNK3dy11ykymQ0YyL83Ni3UoIiLSTDnn/uOcmwD0Az4ErgHamdlfzOzEWpxfClxJcAmjxcBLzrmFZnanmf0g1OwqM1toZl8BVwEXR+Nnqay0zAGouIuISJyKalXPlsTMOO+wXB54bxk7C/1kpvhiHZKIiDRTzrndwPPA86H1aM8mWOnz3VqcO5XgckeR+26N+HwTcFOjBlwLe4d66p2xiEg80rd3HQwKDff8fNXWGEciIiLxwjm3PTTf7rhYx9IQJRrqKSIS1/TtXQejembRuXUKz33+XaxDERERaVLhoZ4JGuopIhKPlPjVQbLPy/ghHfls5RYKivyxDkdERKTJhId6evSrg4hIPNK3dx2dMKA9/jLHR8saviaSiIhIvCgf6ql1/ERE4pO+vevo4Nw2ZKUl8u7CjbEORUREpMmoqqeISHxT4ldHXo9x4sD2vL94I0X+uqzJKyIiEr/86vETEYlr+vauh5MHdWR3SRmPfrAi1qGIiIg0CX+4x0+/OoiIxCN9e9fDkb2zOXlQB/7y0UqWbSyIdTgiIiJRt7fHT0M9RUTikRK/evB4jLt/OJiAc0xdsCHW4YiIiERdSamGeoqIxDN9e9dT27REDmqfzkPTlvPNup2xDkdERCSqdhWXAtAqOSHGkYiISH0o8WuAq4/rA8B97yyNcSQiIiLRtbMwuH5tZoovxpGIiEh9KPFrgJMHd+S6E/vy0bLNWtdPRERaNCV+IiLxTYlfA112VE96ZKfxf28twTkX63BERESiYmehn9REr+b4iYjEKX17N1Cyz8sVY3uzaEM+/5m/LtbhiIiIRMXOQr96+0RE4pgSv0Zw+rBODOmSyW9eWcC3W3fHOhwREZFGV1waINnnjXUYIiJST0r8GoHP6+GJ8w+hpCzA7/+3mLKAhnyKiEjL4pzDtISfiEjcUuLXSDq1TuH4/u2ZtngjL89dGy57LSIi0hI4Bx5lfiIicUuJXyP644+GAHDjqwuY8ORnMY5GRESk8QScw6O8T0Qkbinxa0Rt0xLp3a4VAN+sy2f77pIYRyQiItI4gomfMj8RkXilxK+RvXX1UUy55FAAjnvwI/xlgRhHJCIi0nCavi4iEt+U+P1/e/cdHlWV/3H8fdITSEIChE5Ch4DUSFVEREBR7Aquyrq6rq6urroqimL77S6Wta4N+7quICqKCqI0kU6Q3nsJhIQSEgJJSOb8/pjJZMIECMJkMsnn9TzzMPfcMueeXHLyndPOstDgIPq0rMNFbRM4kFtAq1FTmLFur7+zJSIickY0xk9EJLAp8POB0OAgXr+xi3v7Dx+lsuvgET/mSERE5MxYawnSXw0iIgHLp7/CjTGDjTHrjTGbjDEjy9j/sjFmmeu1wRiT5bGvyGPfJF/m0xeiwkL47i/n0at5bQDOe24mWUc05k9ERAKTxviJiAQ2nwV+xphgNwXqoQAAIABJREFU4A3gEiAZGG6MSfY8xlp7v7W2s7W2M/A68JXH7qPF+6y1Q32VT1/q0CiWz+7oyf9d2QGABz9fTn5hkZ9zJSIicvocFhT2iYgELl+2+HUHNllrt1hrC4BxwBUnOX448JkP8+M3N3ZvymUdGzB9XQZ3f/orDo2QFxGRAOOwFqMWPxGRgOXLwK8RsNNje5crzYsxJhFoBszwSI4wxqQaYxYYY670XTZ9LyjI8PrwLjw8uA3T1mbQYtRk5m/e7+9siYhIJXSqYRIex11jjLHGmJSKypvW8RMRCVyVZZj2MOALa61nP8hEa20KcCPwijGmRVknGmPucAWIqZmZmRWR19/EGMNdF7RgUPt6WAvD313Axr05/s6WiIhUIuUZJuE6Lhq4D1hYUXnTGD8RkcDmy8AvDWjisd3YlVaWYRzXzdNam+b6dwswC+jifRpYa8daa1OstSl169Y90zz7lDGGd25OYdSl7QC4+OXZmu1TREQ8lXeYxLPAc0BeRWXM4dByDiIigcyXgd9ioJUxppkxJgxncOc1O6cxpi0QB8z3SIszxoS73tcB+gBrfJjXCvXHvs0JC3YW/cgvV5I08nu6/30aBYVa7F1EpJo75TAJY0xXoIm19vuKzJjDanYXEZFA5rPAz1pbCNwDTAXWAp9ba1cbY54xxnjO0jkMGGet9ZzxpB2QaoxZDswExlhrq0zgB5D6xAD+1Lc5czbtAyAjJ5/Wj09hd9ZRP+dMREQqK2NMEPAS8GA5jj2rQyEsGuMnIhLIQnx5cWvtZGDycWmjj9t+qozz5gHn+DJv/hYTEco9/VtyILeACUt2udN7j5lB2/rRvHNzNxJr1/BjDkVExA9ONUwiGugAzHLNsFkfmGSMGWqtTfW8kLV2LDAWICUl5Yynk3Yu4F5ZpgYQEZHTpd/gfhQdEcoL13Xi6i6lJztdl57Ds9+tYX26Jn8REalmTjpMwlp7yFpbx1qbZK1NAhYAXkGfLzisxviJiAQyBX6VwEs3dGbbmCHMG9mfRrUiAZi2NoNBr8zmbxOW8+nC7X7OoYiIVITTGCZR4Zzr+PkzByIiciYU+FUiDWtFMndkf7o0reVO+2LJLkZNXEXpIZAiIlJVWWsnW2tbW2tbWGv/7kobba31miDNWtuvIlr7wNnipwXcRUQClwK/Sui+i1oRFxVaKu22j1O56s25jF+8g+y8Y37KmYiIVFvWanIXEZEApsCvEurXJoFfn7iYp4e2JzrcOf/OjHUZLN2RxSNfrqTjUz+yctchP+dSRESqE43xExEJbAr8KiljDCN6J7Hy6UG8cWNXr/1XvTmXwiIHP65Op7BI6/+JiIhvOdTiJyIS0Hy6nIOcHUM6NmBIxyEs3naA6952rnNf6LC0HDUFgA6NYhh3Ry9qhuvHKSIivuGwoBXcRUQCl1r8Asi5SfE8PbS9V/qqtGzemrXJDzkSEZHqwqrFT0QkoKmJKMDc0iuRAcn1SN12gPvGLXOnvz9nK3VrhjMguR6N46L8mEMREamKrMb4iYgENAV+AcYYQ6NakTTs1JAjBUV0blKLnzdkMmbKOp76dg1PfbuGRY9dREJMhL+zKiIiVYjDWoLUT0hEJGDpV3iAMsYwvHtT2jWI4Q99mpXaN+Clnxk1cSWfzN9GkUPr/4mIyJlzLuCuFj8RkUClwK8KCAsJ4r1bUvjfH3sQHhJEdl4hny7cwRPfrKbtE1O0+LuIiJwxazW1i4hIIFPgV0UMSK5H7xZ1uKB13VLpx4osS7Yf9FOuRESkqrBojJ+ISCBT4FfFvHBdJ8ZcfQ7nJsW504a/u4DdWUf9mCsREQl0WsdPRCSwaXKXKiY2MpRh3ZtybbfGOCx8vSyNh79YQe8xMxjQrh5jb+5GkGpuERE5Tc7AT/WHiEigUotfFRUSHERYSBDXpzTh0nPqAzBt7V6en7qe/YfzefvnzTg08YuIiJSTw4EmdxERCWBq8asGXr6hM7efn83IL1fwzbI0lu/MYv6W/SQ3iKHvcWMCRUREymKtRXGfiEjgUotfNRAeEkzXpnFc0bkRew7lMX/LfgBu+WARS7YfxFrLrzsOavZPERE5IefkLv7OhYiI/FZq8atGbu6VyMHcAt6bs9Wdds1b82hbP5p16Tk8eXkytx63JqCIiAhojJ+ISKBTi181EhMRyuOXJbP1n5cy7YG+7vR16TkAPP3tGg4dOeav7ImISCXmsBrjJyISyBT4VUPGGFomRDOkYwOvfYNfnc2WzMMs3nbADzkTEZHKSmP8REQCm7p6VmP/Ht6F14d1ofljk91pew7l0f9fPwNwS69EMnPySc/O4/0R5xJfI8xfWRURET+zVmP8REQCmQK/aswYgzHwy8MXsmFvDp2b1OKGsQvYlHEYgP/M3+4+9ptlaRr/JyJSjWmMn4hIYFPgJzSJj6JJfBQA4+7oyY+r93JNt0YMenk22/YfAZzj/7o0jaNBbAT1YiL8mV0REfEDh0WBn4hIAFPgJ6XUqRnOjT2aAjDlvr58syyNkV+tBODKN+a6jzs3KY6Rl7SlyAHdm8X7Ja8iIlJxHBrjJyIS0BT4yQlFhgUzrHtTHBYem7iy1L7F2w5yzVvzAVjy+ABqRoQQHhLsj2yKiEgFsBYMivxERAKVAj85pRvObULNiBBCggzb9ucydfVelu/Mcu/v9n/T6JYYx5d39S51Xt6xIgAiQhUQiogEOmutJncREQlgCvzklIKDDEM7NXRv/7lfS1o/PoWCQoc7bcn2g9w/fhlDzmlAWtZRoiNC+MfktWQfLWTds4MJ0l8LIiIBzWHR73IRkQDm03X8jDGDjTHrjTGbjDEjy9j/e2NMpjFmmet1u8e+EcaYja7XCF/mU05f6uMDeGhQGwAudwWFE5emcft/Unly0moe+Hw5+w4XUFDk4JEvV/Dsd2vIO1ZEYZGDnDwtEi8iciLlqDvvNMasdNWbc4wxyRWRL43xExEJbD5r8TPGBANvABcDu4DFxphJ1to1xx063lp7z3HnxgNPAimABZa4zj3oq/zK6YmJCOXOC1owuEN9CgodzNmYSbfEeKat3et17IQluwDYlHGYtvWjeWf2FpaPHkhsVKhrQWD9JSEiAuWuO/9nrX3bdfxQ4CVgsK/zZjWrp4hIQPNli193YJO1dou1tgAYB1xRznMHAT9Zaw+4gr2fqIBKTU5PcJChRd2atGsQw9LRA3lvRArTHuh7woXeF2zZz+RVewCYs2kfB3MLaPboZMYv3nHCz/hw7lY+T93pk/yLiFRCp6w7rbXZHps1cH5B6nMOazW1i4hIAPPlGL9GgOdf7LuAHmUcd40xpi+wAbjfWrvzBOc28lVG5expmRDNr09c7N7OO1bE4Fec6wHmFzrYeeAoAHf/71da16sJwDuzt3DDuU3JOlLAK9M28vDgNkSFOR/Np791fsl9fUoTr88qcljyC4vcx4qIVAHlqjuNMXcDDwBhQP+KyJhFLX4iIoHMp2P8yuFbIMla2xFnq97Hp3sBY8wdxphUY0xqZmbmWc+gnJmI0GBmPNiPd27u5rVvw97DAOTkFZKdd4yxs7fw0bxtTEjdxaTlu/l2+W73sdZa9yyhxUZNXEny6KlYWyFfdouIVBrW2jestS2AR4DHyzrmbNePGuMnIhLYfNlUkgZ4NtM0dqW5WWv3e2y+BzzvcW6/486dVdaHWGvHAmMBUlJSFAFUQkFBhgta12VQ+3pMXe09BjAzJ5+OT/3o3v775LWlZgwFGPLaHDZm5PD8tR25qktjDh05xrjFzi/Fs/MKiY0M9e1NiIhUjFPWnccZB7xV1o6zWT9aazXGT0QkwPmyxW8x0MoY08wYEwYMAyZ5HmCMaeCxORRY63o/FRhojIkzxsQBA11pEqAiQoN55+YUXh3Wme/vPY9OjWMBeOzStl7HHh/0AazZk82xIsv945ezZPtBOj1TEigeyC1gw94cjhV5nyciEmDKU3e28tgcAmz0daYcrrAxWMs5iIgELJ8FftbaQuAenAHbWuBza+1qY8wzrlnIAO41xqw2xiwH7gV+7zr3APAszgpwMfCMK00C3BWdG9G+YSz/ur4zIy9py6D29Uvtf/eWFPd7z7UDPd347oJS2/M372fgy7MZM2Wd17EFhQ6KHGoIFpHAUM668x5X3bkM5zg/ny95VPx7VHGfiEjg8umsGNbaycDk49JGe7x/FHj0BOd+AHzgy/yJ/7RMqEnLhJpYa/lL/5YMTK5P47hI4mqEERsZyqGjxxg1pB1Lth8kv9BBaLBhz6E8APKPaxF8bOJKAN6fs5Ul2w8SGxnKzxsymfm3flz44iwGtEvg2m6NufO/v/L2Td0Y3KF0sPnzhky+XLKL14Z3qZibFxE5iXLUnfdVdJ4crrHUWsBdRCRwaTpE8StjDA8ObFMq7ft7z2NLZi71YiKYO9I5WZ21ls2Zhxnw0uyTXm/Zziz3+7GzNwMwbW0G09ZmAHDnf5ewbcyQUueM+GARAP+8+hxqhOu/hIjI8dyBn8b4iYgELH/P6inipXFcFH1b1y2VZoyhZUI0Dw1qQ7fEOHf6l3f1PuF1PltU9vp/RwuKuPn9hdz20WJ27D/iTs/IyScn7xjZeceYvSGTpJHfsznzMBk5eWd4Ryc2fvEO9mb77voiImeDe4yfAj8RkYCl5g0JKHdf2JK7L2zJgdwCdmcdpUOjWNY+M5jHJq6kZUJNHA7L1v25tK4X7R7zVz8mgnSP4Krd6B/c76evy3C/HzVxJfM2e040Cxf962cAr1ZCT7sOHqFxXNRp38v+w/k88uVK2jWIYcp955/2+SIiFaV4jJ/iPhGRwKXATwJSfI0w4muEARAZFszLN3Qutb+wyEFCdDiXd2pIQaGDvs/PZH9uwUmveXzQ5+mWDxZxOO8YbepH84+rzsG4/vr5Zlka941bxrg7ehIdEcLPGzL5c7+W7vOKHJaFW/fTu0Udr2sWuGYh3XPoqNe+/MIiDIawEDXKi4j/Fa+Xqlk9RUQClwI/qZJCgoO4umtjAEKDg1jyxMUUFjm44IVZpGUd5bu/nMf945exMeNwua43e4Nz8eNfd2RxtKCIHs1rs3ZPNv+Zvx2AxVsP8K+fNgDw/A/reX9EChe1q8c7szfz/A/reePGrrSuV5Mt+3Lp3zaB0OAgjhY4F6Qvclhy8ws5eqyIOjXDAUgePZWk2lFMf7Df2SwWEZHfpGRWTwV+IiKBSoGfVBshwUHMHdmfY0UOQoOD+PH+vkxI3UVYSBBb9+Xy6vSSpbD6t01ghkc3UE9fL9vN18t2l0orDvqK3fZxKoseu4h3Z28B4O7//ere9+wV7bm5VxJzXS2MRQ7LZa/PYeu+XLaNGULesSKKHJbNmbnc/P5CPrmtx1m5/7Jk5x0jJiLUZ9cXkaqheIyfZvUUEQlcCvyk2gkNdnafNMZw/blN3Onnt6pDpya12L4/l8TaNbh//DL6tq7LoOT6jE/dwe96JFJkLR2f+vFEly6l+z+ml5n+xDer6d+uHk98vQqAwiLL1n257v1tnygZg/jLxn2nfX9l2XXwCA1jI4GSP9zWp+cw6JXZvDqsM1d0bnRWPkdEqiZrtY6fiEigU+An4pKSFA9Ay4RoAP59Y1f3vjv6tnC/f/bKDu6gDeDqLo0YeWlbuv+97ECvLP/4fq37ffFYPyj548qTw2HZfegon6fuokXdGtSNDqd3izo8MH4Za9NzmHBnL6JCg8v8Jv7hL5ZTKyqMsbO3UC8mnL3Z+fz8UD8Sa9cgLcs5o+m4RTsV+InISRVpOQcRkYCnwE/kNN3cM5GYiBC6N4snJCiIuKhQQoKDWPPMIJJHTwVg8agB9HluBgXHLTafVDuKbfuP8P3KPWVe+91ftnilTViyk0e+XFkqbfmTA/lqaRoAHZ6cSt3ocB4e1IacvEL+cF4zrLV8u2IPn6fucp+zNzsfgPmb95NYu4Y7ff6W/SzfmUVywxhCg4OYtT6D9g1jqRsd/htKR0SqIi3nICIS+BT4ifwGZbWQRYWF8OntPYiJCKVudDhLn7iYbftzefzrVSzdkcWL13WiWZ0ornlr/gmv+4/J67zSnpy02iut09Olu5tm5uTz0BcrALiwbQIXvjjrhJ+xdk82mTn5/OGj1JL7eWMud17Qgj/1bc7vP1zMuUlxTLizN9Za9wymJ7M3O4/lO7MY2L7+KY8VkcDj0HIOIiIBT3PFi5xFfVrW4ZzGsQDUCA+hfcNY/nd7Tx4Z3JYrOjekS5M4Hh/SjuWjB/Lgxa0BGOYxztDT40PaAZB3zFHm/hM5WdAH8PH87Vz5xlyv9LV7slm+KwuA1O0HeXHqepo9OplFWw+Qm1/IqrRD7mMLCh1MSN1Jbn4hADe+u4A7PllCfmFRmZ/59dI0lu3MYsQHixg1cWWZxxT7YVU68zadnbGNv9Wr0za6Z3IVEXBoOQcRkYCnFj8RH4sMC+aufiVjBG8/vzkA9/RvyS29koiNCqVp7Sie/2E9oy9L5sYeTXnvly1c07Uxy3cd4tvlpWcQjYkIITvPGXBFh4eQ4wq+yjIwuR4/rtnrlZ6W5b124M8bMt2BnLXw75mbAJi4NI1//biehVsPMKJXIk3io4ivEcZDX6xgzZ5sLuvYkM2ZzslpMrLzuX/8MlKS4unTsjZLd2TRp2Vt/jp+WanP+vtV55wwz3f+dwkA28YMcaf9ddxSvl62u1SaL708bYNXHkSqMy3nICIS+BT4ifiJMYbYKOdSCrf2boa1cFPPRMJCgrinfysAnr+mIz2bx3Neyzpk5uRz7dvz+fzOXsRFhbHnUB4J0eFMWZXOgHYJjFu8k0/mb+dwfiGvDuvMwOT6vDVrEz+u2UtEaFC5Wg5Ttx/0Svts0Q73+49d6xZe3cXZ1XXlrkOl9i/aeoDU7QdJ3X6Qt3/eDMBLP5W/TDKy80ptz96QScfGsV7LZwBsysjBGEOLujXL/wHAgdwC9mbn0a5BTJn7y5pgR6S603IOIiKBT109RSqByLBg7r6wJWEhQV7pv+uRSGLtGqQkxbNtzBDa1o+hXkwEnZvUomGtSG47rxmJtWvwyOC2jL48GYAOjWKJDAvm/NZ1gdPvLnoqxRPLpG4/WOraD05YXq7z16Vn85/521i7J5vt+3NJP5THkYLCUktgrEvP5pYPFvGPySUzoD73Q8kYyAEvzeaif/182nm/7u15XPLqLycM8PI9JuRxOCyfzN9Gdt6x0/4ckarEoeUcREQCnlr8RKqQ61OacFWXRu61Cs9NiueeC1tSKyqUd2ZvITMnn7dv6sqg9vXZdfAo69JzuDi5HlsyD7MlM5fb/1My4csDF7emfcMYbvvYmWYMzHmkP33GzDjjfA5+5ZdTHjNznXOM3Ve/prnT3pq1mTv7tuDgkYKTnvvKtA0k1o7iqi6NvfYVd0vNPlrobnH1dKSgZJzirA0ZPPHNajZn5vLU0PanzLNIVeUe46euniIiAUuBn0gVUxz0FfvboDYA/K5HIg5rqRHu/G/fJD6KJvFRADSvW5PmdWsy5upzeHTiSqyFejHhXNSuHt/95Twue30OifFRNKoVydND2/Pi1PVc1qkBny3a6bP7WOLqdlroKN0y1+mZ0jOabsrI4ZJXf+HBgW0YM2Udw7s3dXc/9Qz8/vXjega0q+feXpueTc/mtb0+N9djzOS2fc61DvMLz26L6fHmbdpHQkwELRNOr9uqSEUpcs/qqcBPRCRQKfATqSYiw4JPecyw7k25pEMD3p69mStd4/jaN4zh2Ss70M/VbXRE7yRu6ZWIMYaRg9tx3vMzyHFNNtMyoSY39WhKbkERrRJqMn1tBj+uSWfUkGT+NmE5PZrFs3DrgXLld9pa70lpynLvZ8s4VmQZM8XZDdRzzGGxeZv38fqMTbw+YxP1YyJIz87jiyW76Nm8NkUOy77D+dSLiQDg04Ul52e5WhZrlKPsjhQUkjx6Kk8Pbc+I3knlyvs/J6/l+5V72HXQOdmOJpORyqq4Z7Rm9RQRCVwK/ESklNioUB4Z3Na9bYzh5p6JpY4p/tY/NiqU5aMHkpGTT2RosFfXyYHt6/McHQFnUJjcIIasowVgYcPew7z443qW7cxyH9+xcSz92iTw2vSN5c5v3rGyl5AA50ylL0xdx6q0bHdaXI0w0rPzmLNxH69N30h0RAhPf7uGKfedT7sGMe5JaQByXd0+Dx4pPcZv/ub9rNiVxZ8uKJmtdf9hZ5D4xsxNJw38rLU8/vUqru3WmHdmbynXPc7ZuI/5W/bx0KC2pz5YxAdKZvX0c0ZEROQ30+QuInJGgoIM9WMjyhwv56lzk1qEhQSREB1BQkwE57Wqw619kgBoEOtsbfvrgFbc1qeZ+5z+bROY88iFpa7z0a3ncpWrNRJgy77cE37miA8WlQr6wLleIUB6dh4v/bSBCam7AJixLsPr/CMFzpbMtKwjpdIf/3ol/5yyjlembeCtWc5AMdd17Km6hR7OL+TThTu46s15Jzxmx/4jFHhc56b3F/LGzM1nNOPojv1HOHySpT9ETsY9uYsiPxGRgKXAT0T8pmvTOFIS4/j7VR3Y/I9L6d+2HrFRocwd2R+A81vVITayJKDcNmYI/dokULtGmNe1xt/Rkxev63TaeVjjCgTXp+eQdaSAJvGRgDMYLe6CuWT7QTZlHObNWZvYlHGYhGhnoPrKtI0898M6cvML3d1dT9YC+daszbz004aT5mfngSP0fWEmr8/wbvU82ZqNny7c7h4XWZa+L8xk+NgFJ/1skRNxL+egMX4iIgFLXT1FxG+axEfxxV29vdIb1Ypk+ZMDiQ4PofjvzOiIkl9Xf7qgBZ2a1OLcpHjGTFlLo7hIuiXG0aN5bR75coW7W9qJlLXw/aTlu5m0vGS9wD2H8thzyLmu4LEiy4CXnEtHPP/DepKPWwNw8bYDvDzNGajlFzqYs3EfaVlHKHJA2wbRdG0aB5RejqIs1lr+6JpZdXPmYQBu/3ixe/+Vb8xl+gMXMG7xTga3r0+cRwA8auIqoOxxgsUthSvTDpF3rIhRE1fx0KA21He1tIqcipZzEBEJfAr8RKRS8mzpe/N3XUsFW3Wjw7m8U0MAXhnWpdR5s/7Wj5Vph9h3OJ+k2jWoER7Ck5NWcf+A1vywKp2EmHBu6pnI4m0HufezpQBc2KYuM9dnuq9xUdsEppfR9bNYcSthsd9/uLjU9k3vLyy1fVnHBidtjSu2+1Ae69JzAGgSF8XurKNMW1uSjy2Zuazdk8OjX61k5roMxt6SQpHDuv8oP96S7Qf424QVTLizlztt6up0vvx1F0UOh7vsihyWZTsP0i0x/pR5lOrJ4dByDiIigU6Bn4hUepee06Dcx3ouU1Hsu7+cD8BFHss5DO0UySs/bWDLvlyeuaID5z8/072va2LcSQM/gFpRoWQdKd/C7t+t2FOu4zKy89zvcwsKWb072+uY/bn5AGQezidp5PcAPHV5cqljPlmwnZrhwXw0bztb9+WSuq0k6CyOEY95tIq+/fNmXpi6ngl39uLcJAV/4q3IajkHEZFApzF+IlJtfXJ7D569oj1N4qNY9+xgd3qMR7fSsJDSvyY/vPVczm9Vh/F39OKGlCal9j15eTL92ybQOC7yN+XHc8KX3Pwi0j0CwWI3v7/Itb+kq+pT364pdcwTX6/i/vHLyclzBqZ3/neJe1/xAvVH8gtJ3eZcWqN4wpvdWUe9Pu/zxTv5fPFOrLXsOXSUvdl5XPHGXNIPeefN05GCQo4VOVifnsNLP204o4lpxP+0nIOISOBTi5+IVFuNakVyc68kACJCg5k7sj+Hjhyjed0abN13hJBgw/DuTZm+di9FDkuRtfRrXZcL2yQA8Ny1Hbm8U0Nuen8hEaFB3NqnGbd6zEr64OfL+fLXXfRsHs8dfZvz3wU7ypw9tCwTl6YxcWnaCfdv2Hu4zPT3filZIqKsFsniYHLm+kxmrs9k7sj+7lYcz9hs+c4sbv1oMQdyXctUzNrE9v1HOL9VHZbvzKLnP6ez/MmBpG47QJ+WdUg/lEejuEhCg52BcvLoqZzfqg7LdmSRk1/IH89vRnTEyWd+lcpLyzmIiAQ+U5W+hU1JSbGpqan+zoaIVDN7s/MICTLUrhleKj03v5Bxi3cyvHsTosKc37P9e8ZGXvxxA9d2a8wXS5xLSVzZuSFfL9vtdV1faF63BlsyS5bA+EOfZuzOOsoPq9P5c78WLNl+kE5NajG2HGsM9m5Rm3mb93NF54Z8s2w3V3dpxEs3dMZaS7NHJ5c6tn5MBAseu4jD+YUEGdzl8VsZY5ZYa1PO6CKVlDFmMPAqEAy8Z60dc9z+B4DbgUIgE/iDtXb7ya55pvXjrPUZ/P7DxXz1597uyYpERKRyOlEdqRY/EZEzVC+m7Nkxa4SHcNt5zUql3dO/FTf3SiI2MpT4GmFc0LoufVrWIb/QwZRV6V7XuKJzQ2qEh7B46wE2Zhzm4uR6/LRmr3t/kIGnhrZnePemvD5jE69N914GwpNn0Afwwdyt7vdvutYkXLj1wMlv+LhrfeMKWr9amsb15zY5YUvjxr05XPPWPO7p35I7+rYo12dUN8aYYOAN4GJgF7DYGDPJWuvZn3cpkGKtPWKMuQt4HrjBl/kqmdVTTX4iIoFKgZ+ISAUrnrH0sUvbudPeuqkb/5yylq2ZuTx9RXtW7DpEdHgIvVvWAWDXwSOsSstmcIf6/LrjIHM27mPm+gz+e1sPaoQ7f5U/cHFrPpyzlcbxUe5xex/eei6PT1xFmsf4vbDgIAqKTr7QfHmUNQZx2EnWCpy1PpPsvEI6NIw948+uwroDm6y1WwCMMeOAKwB34Getnelx/ALgJl9nyuF6XDSrp4hI4PJp4Hcm3VWMMUXAStehO6y1Q32ZVxERf3v0kpJAsEFs6QliGsdF0TjOOVtp16ZxdG0ax70XtfK6RuoTAwgyhvxCB4dpesL/AAALBUlEQVSOHqNRrUjmjuzPnI37uOn9hdSPiaBbYhzfrzzxTKNRYcH8uV8LPpq3jV8e7s/Ir1a4W/Xe/F1X3py1ieu6NeHJSatP6/7+Pnkt0eEh9GpR+7TOq2YaATs9tncBPU5y/G3AFJ/mCM9ZPX39SSIi4is+C/zOQneVo9bazr7Kn4hIVRQeEgxAaHAQNcNLfsWf16oO80b2p0FsBFv25RIeGsRfL2pN/dgIhr+7gJt6NuX16ZvYsi+XNc84Zzi9p78zsLyySyN34HfpOQ3cy2ucbuAHkBATriUBzhJjzE1ACnDBCfbfAdwB0LRp0zP6rOL5ADSrp4hI4PLlcg7u7irW2gKguLuKm7V2prX2iGtzAdDYh/kREanWGtaKxBhDi7o1een6zjStHUVYSBBf3tWbq7o0ZvJ957N89ECv84pnMT3ei9d1okOjmFJpTV1rKL5yQ8n3dtenlPxqrx9b9nhIcUsDPNcJaexKK8UYMwAYBQy11uaXdSFr7VhrbYq1NqVu3bpnlKninsEa4yciErh82dXzTLurRBhjUnF2Ax1jrf367GdRRESKRYQGExEaXOa+qX/tS3Ze6Ulbru3WmGu7NebGdxcwb/N+nrw8mSEdG5B/zEGT+Ch6Nq/NqrRDDEiuxyOD2zI+dSdDXK2FckKLgVbGmGY4A75hwI2eBxhjugDvAIOtteVbH+QMOdwtfhXxaSIi4guVYnKXE3RXSbTWphljmgMzjDErrbWbyzj3rHVlERGRsrWpH33Cfe+NSCE3v4i60aWXs6gfG+Fu4atdM5w/92vp0zxWBdbaQmPMPcBUnOPjP7DWrjbGPAOkWmsnAS8ANYEJrm6zPh8H37dVXb77y3nucaYiIhJ4fBn4nW53lQs8u6tYa9Nc/24xxswCugBegZ+1diwwFpzrFJ3F/IuISDlEhYWc8bp8UsJaOxmYfFzaaI/3Ayo6T7FRocRGaTZWEZFA5stOG+7uKsaYMJzdVSZ5HuDRXWWoZ3cVY0ycMSbc9b4O0AePqaxFRERERESk/Hz2Fe0ZdldpB7xjjHHgDE7HHDcbqIiIiIiIiJSTT/vm/NbuKtbaecA5vsybiIiIiIhIdaH5uURERERERKo4BX4iIiIiIiJVnAI/ERERERGRKk6Bn4iIiIiISBWnwE9ERERERKSKU+AnIiIiIiJSxSnwExERERERqeKMtdbfeThrjDGZwPYzvEwdYN9ZyE5VojLxpjIpm8rFm8rE29kok0Rrbd2zkZnqQPWjT6lcvKlMvKlMvKlMyuazOrJKBX5ngzEm1Vqb4u98VCYqE28qk7KpXLypTLypTAKTfm5lU7l4U5l4U5l4U5mUzZfloq6eIiIiIiIiVZwCPxERERERkSpOgZ+3sf7OQCWkMvGmMimbysWbysSbyiQw6edWNpWLN5WJN5WJN5VJ2XxWLhrjJyIiIiIiUsWpxU9ERERERKSKU+DnYowZbIxZb4zZZIwZ6e/8VBRjTBNjzExjzBpjzGpjzH2u9HhjzE/GmI2uf+Nc6cYY85qrnFYYY7r69w58xxgTbIxZaoz5zrXdzBiz0HXv440xYa70cNf2Jtf+JH/m25eMMbWMMV8YY9YZY9YaY3pV92fFGHO/6//OKmPMZ8aYiOr4rBhjPjDGZBhjVnmknfazYYwZ4Tp+ozFmhD/uRbypjlQdeTzVkaWpfiyb6sjKVT8q8MP5ywt4A7gESAaGG2OS/ZurClMIPGitTQZ6Ane77n0kMN1a2wqY7toGZxm1cr3uAN6q+CxXmPuAtR7bzwEvW2tbAgeB21zptwEHXekvu46rql4FfrDWtgU64SyfavusGGMaAfcCKdbaDkAwMIzq+ax8BAw+Lu20ng1jTDzwJNAD6A48WVwZiv+ojlQdeQKqI0tT/Xgc1ZFuH1FZ6kdrbbV/Ab2AqR7bjwKP+jtffiqLb4CLgfVAA1daA2C96/07wHCP493HVaUX0Nj1H7E/8B1gcC6mGXL8MwNMBXq53oe4jjP+vgcflEkssPX4e6vOzwrQCNgJxLt+9t8Bg6rrswIkAat+67MBDAfe8UgvdZxefvu5qo4suXfVkVZ1ZBnlofqx7HJRHVlSFpWiflSLn1Pxg1lslyutWnE1qXcBFgL1rLV7XLvSgXqu99WlrF4BHgYcru3aQJa1ttC17Xnf7jJx7T/kOr6qaQZkAh+6uve8Z4ypQTV+Vqy1acCLwA5gD86f/RL0rBQ73Wejyj8zAUo/F1RHHkd1ZGmqH8ugOvKk/FI/KvATAIwxNYEvgb9aa7M991nnVwvVZvpXY8xlQIa1dom/81LJhABdgbestV2AXEq6JgDV8lmJA67AWek3BGrg3Z1DqH7PhlQtqiNLqI4sk+rHMqiOLJ+KfDYU+DmlAU08thu70qoFY0wozgrtU2vtV67kvcaYBq79DYAMV3p1KKs+wFBjzDZgHM6uLK8CtYwxIa5jPO/bXSau/bHA/orMcAXZBeyy1i50bX+Bs6Krzs/KAGCrtTbTWnsM+Arn81Pdn5Vip/tsVIdnJhBV65+L6kgvqiO9qX4sm+rIE/NL/ajAz2kx0Mo1y1AYzoGnk/ycpwphjDHA+8Baa+1LHrsmAcUzBo3AOa6hOP0W16xDPYFDHk3VVYK19lFrbWNrbRLOZ2GGtfZ3wEzgWtdhx5dJcVld6zq+yn2rZ61NB3YaY9q4ki4C1lCNnxWc3Vd6GmOiXP+XisukWj8rHk732ZgKDDTGxLm+KR7oShP/Uh2pOtJNdaQ31Y8npDryxPxTP/p7sGNleQGXAhuAzcAof+enAu/7PJzNyyuAZa7XpTj7VE8HNgLTgHjX8Qbn7G6bgZU4Z2ry+334sHz6Ad+53jcHFgGbgAlAuCs9wrW9ybW/ub/z7cPy6Aykup6Xr4G46v6sAE8D64BVwCdAeHV8VoDPcI7hOIbz2+/bfsuzAfzBVT6bgFv9fV96uX8uqiNVR5ZVPqojS8pC9WPZ5VLt68jKVD8a14VERERERESkilJXTxERERERkSpOgZ+IiIiIiEgVp8BPRERERESkilPgJyIiIiIiUsUp8BMREREREaniFPiJVBLGmCJjzDKP18izeO0kY8yqs3U9ERGRiqL6UeTsCPF3BkTE7ai1trO/MyEiIlLJqH4UOQvU4idSyRljthljnjfGrDTGLDLGtHSlJxljZhhjVhhjphtjmrrS6xljJhpjlrtevV2XCjbGvGuMWW2M+dEYE+m3mxIRETlDqh9FTo8CP5HKI/K4riw3eOw7ZK09B/g38Ior7XXgY2ttR+BT4DVX+mvAz9baTkBXYLUrvRXwhrW2PZAFXOPj+xERETkbVD+KnAXGWuvvPIgIYIw5bK2tWUb6NqC/tXaLMSYUSLfW1jbG7AMaWGuPudL3WGvrGGMygcbW2nyPayQBP1lrW7m2HwFCrbX/5/s7ExER+e1UP4qcHWrxEwkM9gTvT0e+x/siNMZXREQCn+pHkXJS4CcSGG7w+He+6/08YJjr/e+AX1zvpwN3ARhjgo0xsRWVSRERkQqm+lGknPSNhkjlEWmMWeax/YO1tnjK6jhjzAqc30oOd6X9BfjQGPMQkAnc6kq/DxhrjLkN5zeXdwF7fJ57ERER31D9KHIWaIyfSCXnGsOQYq3d5++8iIiIVBaqH0VOj7p6ioiIiIiIVHFq8RMREREREani1OInIiIiIiJSxSnwExERERERqeIU+ImIiIiIiFRxCvxERERERESqOAV+IiIiIiIiVZwCPxERERERkSru/wF/kIoWwtog3gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtenemos las predicciones de los datos test \n",
        "sc_X = StandardScaler()\n",
        "x_test_scaled = sc_X.fit_transform(X_test)\n",
        "y_pred  = classifier.predict(x_test_scaled)\n",
        "\n",
        "#y_test, y_pred\n",
        "y_test_dummy = np_utils.to_categorical(y_test)\n",
        "y_pred_dummy = np.vectorize(lambda x: int(x >= 0.5))(y_pred)"
      ],
      "metadata": {
        "id": "WvHoBpiVgu_r"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos las métricas de evaluación del modelo clasificador con RNA\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "cm = confusion_matrix(y_test_dummy.argmax(axis=1), y_pred_dummy.argmax(axis=1))\n",
        "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "print('Model Performance')\n",
        "print('Accuracy = {:0.4f}%.'.format(metrics.accuracy_score(y_test_dummy, y_pred_dummy)))\n",
        "print('Recall = {:0.4f}%.'.format(np.mean(recall)))\n",
        "print('Precision = {:0.4f}%.'.format(np.mean(precision)))\n",
        "print('Matrix confussion')\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVTweSyUlpnC",
        "outputId": "6b5141c9-3009-4fc1-d658-b6fc1f17b94c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Accuracy = 0.7305%.\n",
            "Recall = 0.7133%.\n",
            "Precision = 0.7211%.\n",
            "Matrix confussion\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[54,  7,  2,  1,  1,  0,  0],\n",
              "       [13, 26,  5,  2,  3,  3,  0],\n",
              "       [ 3, 10, 32,  2,  5,  1,  0],\n",
              "       [ 8,  2,  1, 32,  8,  4,  0],\n",
              "       [ 5,  3,  7,  5, 38,  1,  0],\n",
              "       [ 0,  0,  1,  3,  5, 55,  0],\n",
              "       [ 2,  0,  0,  0,  0,  0, 73]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}